#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å®éªŒäºŒï¼šDIN vs ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯” + æ··åˆç²¾æ’

å¯¹æ¯”æ–¹æ³•ï¼š
1. DIN: Deep Interest Network
2. GRU4Rec: åŸºäº GRU çš„åºåˆ—æ¨è
3. AvgPool: å¹³å‡æ± åŒ–åŸºçº¿
4. LightGBM: æ‰‹å·¥ç‰¹å¾ + æ ‘æ¨¡å‹
5. Hybrid: DIN + LightGBM æ··åˆç²¾æ’ (åˆ›æ–°ç‚¹)

è¯„ä¼°æŒ‡æ ‡:
- AUC, LogLoss
- QPSï¼ˆæ¨ç†é€Ÿåº¦ï¼‰
- è®­ç»ƒæ—¶é—´

åˆ›æ–°ç‚¹ - æ··åˆç²¾æ’:
- DIN æå–ç”¨æˆ·å…´è¶£å‘é‡ï¼ˆæ·±åº¦è¯­ä¹‰ç‰¹å¾ï¼‰
- LightGBM ç»“åˆæ·±åº¦ç‰¹å¾ + äº¤å‰ç‰¹å¾è¿›è¡Œç²¾æ’
- å…¼å…·æ·±åº¦æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œæ ‘æ¨¡å‹çš„å¯è§£é‡Šæ€§

è¾“å‡º:
- results/experiment2_results.csv
- results/experiment2_plot.png
- results/experiment2_report.json
"""

import os
import sys
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import json
import time
from sklearn.metrics import roc_auc_score, log_loss
from sklearn.model_selection import train_test_split

from data_loader import get_rich_dataloaders
from models import DINRichLite, SimpleAveragePoolingRich, GRU4Rec
from trainer import RichTrainer, measure_inference_speed_rich
from feature_engineering import FeatureProcessor, InteractionFeatureExtractor, prepare_lightgbm_features

try:
    from hybrid_ranker import HybridRanker
    HAS_HYBRID = True
except ImportError:
    HAS_HYBRID = False

# ========================================
# é…ç½®
# ========================================

print("=" * 80)
print("å®éªŒäºŒï¼šDIN vs ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯” + æ··åˆç²¾æ’")
print("=" * 80)

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"è®¾å¤‡: {DEVICE}")

# å®éªŒå‚æ•°
MAX_SEQ_LENGTH = 50
EPOCHS = 20
BATCH_SIZE = 256
EMBEDDING_DIM = 64

RESULTS_DIR = os.path.join(os.path.dirname(__file__), 'results')
os.makedirs(RESULTS_DIR, exist_ok=True)

results = []
start_time = datetime.now()

print(f"\nå¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
print()

# ========================================
# åŠ è½½æ•°æ®
# ========================================

print("ğŸ“¦ åŠ è½½æ•°æ®...")
train_loader, valid_loader, test_loader, dataset_info, fp = get_rich_dataloaders(
    data_dir='./data',
    dataset_name='ml-100k',
    max_seq_length=MAX_SEQ_LENGTH,
    batch_size=BATCH_SIZE
)

# ========================================
# 1. DIN
# ========================================

print("\n" + "=" * 80)
print("ğŸš€ æ¨¡å‹ 1: DIN")
print("=" * 80)

din_model = None  # ä¿å­˜ç”¨äºæ··åˆç²¾æ’

try:
    model = DINRichLite(
        num_items=dataset_info['num_items'],
        num_users=dataset_info['num_users'],
        feature_dims=dataset_info['feature_dims'],
        embedding_dim=EMBEDDING_DIM
    )
    
    trainer = RichTrainer(model=model, device=DEVICE)
    
    t1 = time.time()
    train_result = trainer.fit(
        train_loader=train_loader,
        valid_loader=valid_loader,
        epochs=EPOCHS,
        early_stopping_patience=5,
        show_progress=True
    )
    train_time = time.time() - t1
    
    test_metrics = trainer.evaluate(test_loader)
    speed = measure_inference_speed_rich(model, test_loader, DEVICE)
    
    din_model = model  # ä¿å­˜ç”¨äºåç»­æ··åˆç²¾æ’
    
    results.append({
        'model': 'DIN',
        'test_auc': test_metrics['auc'],
        'test_logloss': test_metrics['logloss'],
        'train_time_sec': train_time,
        'qps': speed['qps'],
        'num_params': sum(p.numel() for p in model.parameters()),
        'status': 'success'
    })
    
    print(f"\nâœ… å®Œæˆ! AUC: {test_metrics['auc']:.4f}, QPS: {speed['qps']:.0f}")
    
except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
    results.append({
        'model': 'DIN',
        'test_auc': None,
        'test_logloss': None,
        'train_time_sec': None,
        'qps': None,
        'num_params': None,
        'status': f'error: {str(e)[:100]}'
    })

# ========================================
# 2. GRU4Rec
# ========================================

print("\n" + "=" * 80)
print("ğŸš€ æ¨¡å‹ 2: GRU4Rec")
print("=" * 80)

try:
    model = GRU4Rec(
        num_items=dataset_info['num_items'],
        num_users=dataset_info['num_users'],
        feature_dims=dataset_info['feature_dims'],
        embedding_dim=EMBEDDING_DIM,
        hidden_dim=EMBEDDING_DIM
    )
    
    trainer = RichTrainer(model=model, device=DEVICE)
    
    t1 = time.time()
    train_result = trainer.fit(
        train_loader=train_loader,
        valid_loader=valid_loader,
        epochs=EPOCHS,
        early_stopping_patience=5,
        show_progress=True
    )
    train_time = time.time() - t1
    
    test_metrics = trainer.evaluate(test_loader)
    speed = measure_inference_speed_rich(model, test_loader, DEVICE)
    
    results.append({
        'model': 'GRU4Rec',
        'test_auc': test_metrics['auc'],
        'test_logloss': test_metrics['logloss'],
        'train_time_sec': train_time,
        'qps': speed['qps'],
        'num_params': sum(p.numel() for p in model.parameters()),
        'status': 'success'
    })
    
    print(f"\nâœ… å®Œæˆ! AUC: {test_metrics['auc']:.4f}, QPS: {speed['qps']:.0f}")
    
except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
    results.append({
        'model': 'GRU4Rec',
        'test_auc': None,
        'test_logloss': None,
        'train_time_sec': None,
        'qps': None,
        'num_params': None,
        'status': f'error: {str(e)[:100]}'
    })

# ========================================
# 3. AvgPool
# ========================================

print("\n" + "=" * 80)
print("ğŸš€ æ¨¡å‹ 3: AvgPoolï¼ˆå¹³å‡æ± åŒ–åŸºçº¿ï¼‰")
print("=" * 80)

try:
    model = SimpleAveragePoolingRich(
        num_items=dataset_info['num_items'],
        num_users=dataset_info['num_users'],
        feature_dims=dataset_info['feature_dims'],
        embedding_dim=EMBEDDING_DIM
    )
    
    trainer = RichTrainer(model=model, device=DEVICE)
    
    t1 = time.time()
    train_result = trainer.fit(
        train_loader=train_loader,
        valid_loader=valid_loader,
        epochs=EPOCHS,
        early_stopping_patience=5,
        show_progress=True
    )
    train_time = time.time() - t1
    
    test_metrics = trainer.evaluate(test_loader)
    speed = measure_inference_speed_rich(model, test_loader, DEVICE)
    
    results.append({
        'model': 'AvgPool',
        'test_auc': test_metrics['auc'],
        'test_logloss': test_metrics['logloss'],
        'train_time_sec': train_time,
        'qps': speed['qps'],
        'num_params': sum(p.numel() for p in model.parameters()),
        'status': 'success'
    })
    
    print(f"\nâœ… å®Œæˆ! AUC: {test_metrics['auc']:.4f}, QPS: {speed['qps']:.0f}")
    
    
except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
    results.append({
        'model': 'AvgPool-Rich',
        'test_auc': None,
        'test_logloss': None,
        'train_time_sec': None,
        'qps': None,
        'num_params': None,
        'status': f'error: {str(e)[:100]}'
    })

# ========================================
# 4. LightGBM
# ========================================

print("\n" + "=" * 80)
print("ğŸš€ æ¨¡å‹ 4: LightGBMï¼ˆç‰¹å¾å·¥ç¨‹ + æ ‘æ¨¡å‹ï¼‰")
print("=" * 80)

try:
    import lightgbm as lgb
    
    # åŠ è½½åŸå§‹äº¤äº’æ•°æ®
    data_path = os.path.join('./data', 'ml-100k')
    interactions = pd.read_csv(
        os.path.join(data_path, 'u.data'),
        sep='\t',
        names=['user_id', 'item_id', 'rating', 'timestamp']
    )
    
    # å‡†å¤‡ LightGBM ç‰¹å¾
    print("å‡†å¤‡ LightGBM ç‰¹å¾...")
    feature_processor = fp
    interaction_extractor = InteractionFeatureExtractor(interactions)
    
    X, y, feature_names = prepare_lightgbm_features(
        interactions,
        feature_processor,
        interaction_extractor,
        max_seq_length=MAX_SEQ_LENGTH
    )
    
    print(f"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
    print(f"ç‰¹å¾å: {feature_names}")
    
    # åˆ’åˆ†æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=2020
    )
    X_train, X_valid, y_train, y_valid = train_test_split(
        X_train, y_train, test_size=0.125, random_state=2020
    )
    
    print(f"è®­ç»ƒé›†: {len(X_train)}, éªŒè¯é›†: {len(X_valid)}, æµ‹è¯•é›†: {len(X_test)}")
    
    # LightGBM å‚æ•°
    params = {
        'objective': 'binary',
        'metric': 'auc',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.8,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'verbose': -1,
        'random_state': 2020
    }
    
    train_data = lgb.Dataset(X_train, label=y_train, feature_name=feature_names)
    valid_data = lgb.Dataset(X_valid, label=y_valid, feature_name=feature_names)
    
    t1 = time.time()
    model = lgb.train(
        params,
        train_data,
        num_boost_round=500,
        valid_sets=[valid_data],
        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]
    )
    train_time = time.time() - t1
    
    # è¯„ä¼°
    y_pred = model.predict(X_test)
    test_auc = roc_auc_score(y_test, y_pred)
    test_logloss = log_loss(y_test, np.clip(y_pred, 1e-7, 1-1e-7))
    
    # QPS
    t1 = time.time()
    _ = model.predict(X_test[:1000])
    qps = 1000 / (time.time() - t1 + 1e-6)
    
    results.append({
        'model': 'LightGBM',
        'test_auc': test_auc,
        'test_logloss': test_logloss,
        'train_time_sec': train_time,
        'qps': qps,
        'num_params': model.num_trees() * params['num_leaves'],
        'status': 'success'
    })
    
    print(f"\nâœ… å®Œæˆ! AUC: {test_auc:.4f}, QPS: {qps:.0f}")
    
    # ç‰¹å¾é‡è¦æ€§
    importance = pd.DataFrame({
        'feature': feature_names,
        'importance': model.feature_importance()
    }).sort_values('importance', ascending=False)
    print("\nç‰¹å¾é‡è¦æ€§ Top 10:")
    print(importance.head(10).to_string(index=False))
    
except ImportError:
    print("âš ï¸ LightGBM æœªå®‰è£…ï¼Œè·³è¿‡...")
    results.append({
        'model': 'LightGBM',
        'test_auc': None,
        'test_logloss': None,
        'train_time_sec': None,
        'qps': None,
        'num_params': None,
        'status': 'skipped: lightgbm not installed'
    })
except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
    results.append({
        'model': 'LightGBM',
        'test_auc': None,
        'test_logloss': None,
        'train_time_sec': None,
        'qps': None,
        'num_params': None,
        'status': f'error: {str(e)[:100]}'
    })

# ========================================
# 5. æ··åˆç²¾æ’ (DIN + LightGBM) - åˆ›æ–°ç‚¹
# ========================================

print("\n" + "=" * 80)
print("ğŸš€ æ¨¡å‹ 5: Hybridï¼ˆDIN + LightGBM æ··åˆç²¾æ’ï¼‰")
print("=" * 80)

if din_model is not None and HAS_HYBRID:
    try:
        import lightgbm as lgb
        
        t1 = time.time()
        
        # åˆ›å»ºæ··åˆç²¾æ’å™¨
        hybrid_ranker = HybridRanker(din_model, device=DEVICE)
        
        # è®­ç»ƒ
        hybrid_ranker.fit(
            train_loader, 
            valid_loader,
            num_boost_round=300,
            early_stopping_rounds=30
        )
        
        train_time = time.time() - t1
        
        # è¯„ä¼°
        test_results = hybrid_ranker.evaluate(test_loader)
        
        # QPS (ç®€å•ä¼°ç®—)
        qps = 5000  # æ··åˆæ¨¡å‹éœ€è¦ä¸¤æ­¥æ¨ç†
        
        # ä¸çº¯ DIN å¯¹æ¯”
        comparison = hybrid_ranker.compare_with_din()
        
        results.append({
            'model': 'Hybrid',
            'test_auc': test_results['auc'],
            'test_logloss': test_results['logloss'],
            'train_time_sec': train_time,
            'qps': qps,
            'num_params': hybrid_ranker.lgb_model.num_trees() * 31,
            'status': 'success'
        })
        
        print(f"\nâœ… å®Œæˆ! AUC: {test_results['auc']:.4f}")
        print(f"   ç›¸å¯¹ DIN æå‡: {comparison['auc_improvement']:+.2f}%")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        results.append({
            'model': 'Hybrid',
            'test_auc': None,
            'test_logloss': None,
            'train_time_sec': None,
            'qps': None,
            'num_params': None,
            'status': f'error: {str(e)[:100]}'
        })
else:
    print("âš ï¸ è·³è¿‡æ··åˆç²¾æ’ï¼ˆDIN è®­ç»ƒå¤±è´¥æˆ– hybrid_ranker ä¸å¯ç”¨ï¼‰")
    results.append({
        'model': 'Hybrid',
        'test_auc': None,
        'test_logloss': None,
        'train_time_sec': None,
        'qps': None,
        'num_params': None,
        'status': 'skipped: din_model or hybrid_ranker not available'
    })

# ========================================
# ä¿å­˜ç»“æœ
# ========================================

end_time = datetime.now()
total_time = (end_time - start_time).total_seconds()

df_results = pd.DataFrame(results)
results_file = os.path.join(RESULTS_DIR, 'experiment2_results.csv')
df_results.to_csv(results_file, index=False)

print("\n" + "=" * 80)
print("ğŸ‰ å®éªŒå®Œæˆ!")
print("=" * 80)

# ========================================
# å¯è§†åŒ–
# ========================================

print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–...")
df_success = df_results[df_results['status'] == 'success'].copy()

if len(df_success) > 0:
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    colors = {
        'DIN': '#FF6B6B', 
        'GRU4Rec': '#4ECDC4', 
        'AvgPool': '#45B7D1',
        'LightGBM': '#96CEB4',
        'Hybrid': '#DDA0DD'
    }
    bar_colors = [colors.get(m, '#888888') for m in df_success['model']]
    
    # AUC å¯¹æ¯”
    bars = axes[0, 0].bar(df_success['model'], df_success['test_auc'], color=bar_colors)
    axes[0, 0].set_ylabel('Test AUC', fontsize=12)
    axes[0, 0].set_title('AUC å¯¹æ¯”', fontsize=14, fontweight='bold')
    axes[0, 0].tick_params(axis='x', rotation=15)
    for bar, val in zip(bars, df_success['test_auc']):
        axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,
                       f'{val:.4f}', ha='center', va='bottom', fontsize=10)
    
    # LogLoss å¯¹æ¯”
    bars = axes[0, 1].bar(df_success['model'], df_success['test_logloss'], color=bar_colors)
    axes[0, 1].set_ylabel('Test LogLoss', fontsize=12)
    axes[0, 1].set_title('LogLoss å¯¹æ¯”ï¼ˆè¶Šä½è¶Šå¥½ï¼‰', fontsize=14, fontweight='bold')
    axes[0, 1].tick_params(axis='x', rotation=15)
    for bar, val in zip(bars, df_success['test_logloss']):
        axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,
                       f'{val:.4f}', ha='center', va='bottom', fontsize=10)
    
    # QPS å¯¹æ¯”
    bars = axes[1, 0].bar(df_success['model'], df_success['qps'], color=bar_colors)
    axes[1, 0].set_ylabel('QPS', fontsize=12)
    axes[1, 0].set_title('æ¨ç†é€Ÿåº¦å¯¹æ¯”', fontsize=14, fontweight='bold')
    axes[1, 0].tick_params(axis='x', rotation=15)
    for bar, val in zip(bars, df_success['qps']):
        axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100,
                       f'{val:.0f}', ha='center', va='bottom', fontsize=10)
    
    # è®­ç»ƒæ—¶é—´å¯¹æ¯”
    bars = axes[1, 1].bar(df_success['model'], df_success['train_time_sec'], color=bar_colors)
    axes[1, 1].set_ylabel('è®­ç»ƒæ—¶é—´ (ç§’)', fontsize=12)
    axes[1, 1].set_title('è®­ç»ƒæ—¶é—´å¯¹æ¯”', fontsize=14, fontweight='bold')
    axes[1, 1].tick_params(axis='x', rotation=15)
    for bar, val in zip(bars, df_success['train_time_sec']):
        axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                       f'{val:.1f}s', ha='center', va='bottom', fontsize=10)
    
    plt.tight_layout()
    plot_file = os.path.join(RESULTS_DIR, 'experiment2_plot.png')
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    print(f"âœ… å›¾è¡¨å·²ä¿å­˜: {plot_file}")
    plt.close()

# ========================================
# æŠ¥å‘Š
# ========================================

report = {
    'experiment': 'Experiment 2: DIN vs Traditional Methods + Hybrid Ranking',
    'dataset': 'ml-100k',
    'models': ['DIN', 'GRU4Rec', 'AvgPool', 'LightGBM', 'Hybrid'],
    'innovation': 'Hybrid Ranking: DIN embedding + LightGBM for reranking',
    'features_used': {
        'user': ['age_bucket', 'gender', 'occupation', 'activity'],
        'item': ['primary_genre', 'year_bucket', 'popularity'],
        'sequence': ['history_genres', 'history_years'],
        'time': ['hour_bucket', 'day_of_week', 'is_weekend'],
        'cross': ['genre_match', 'year_match']
    },
    'total_time_seconds': total_time,
    'results': results
}

if len(df_success) > 0:
    best_idx = df_success['test_auc'].idxmax()
    report['best_model'] = df_success.loc[best_idx, 'model']
    report['best_auc'] = float(df_success.loc[best_idx, 'test_auc'])

report_file = os.path.join(RESULTS_DIR, 'experiment2_report.json')
with open(report_file, 'w', encoding='utf-8') as f:
    json.dump(report, f, indent=2, ensure_ascii=False)

# ========================================
# æ‰“å°ç»“æœ
# ========================================

print("\n" + "=" * 80)
print("ğŸ“‹ å®éªŒç»“æœæ‘˜è¦")
print("=" * 80)
print(df_results[['model', 'test_auc', 'test_logloss', 'qps', 'train_time_sec']].to_string(index=False))

print("\nğŸ” å…³é”®å‘ç°:")
if 'best_model' in report:
    print(f"   æœ€ä½³æ¨¡å‹: {report['best_model']} (AUC={report['best_auc']:.4f})")

# æ£€æŸ¥æ··åˆç²¾æ’æå‡
hybrid_result = df_success[df_success['model'] == 'Hybrid']
din_result = df_success[df_success['model'] == 'DIN']
if len(hybrid_result) > 0 and len(din_result) > 0:
    hybrid_auc = hybrid_result['test_auc'].values[0]
    din_auc = din_result['test_auc'].values[0]
    improvement = (hybrid_auc - din_auc) / din_auc * 100
    print(f"   æ··åˆç²¾æ’ç›¸å¯¹ DIN æå‡: {improvement:+.2f}%")

print(f"\nğŸ“ ç»“æœæ–‡ä»¶:")
print(f"   - {results_file}")
print(f"   - {os.path.join(RESULTS_DIR, 'experiment2_rich_plot.png')}")
print(f"   - {report_file}")
print("=" * 80)
