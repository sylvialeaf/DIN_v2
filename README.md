# DIN åºåˆ—æ¨èç ”ç©¶é¡¹ç›®

<p align="center">
  <img src="https://img.shields.io/badge/PyTorch-2.0+-red.svg" alt="PyTorch">
  <img src="https://img.shields.io/badge/Python-3.8+-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/CUDA-11.8+-green.svg" alt="CUDA">
  <img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License">
</p>

ä¸€ä¸ª**å®Œå…¨ç‹¬ç«‹å®ç°**çš„åºåˆ—æ¨èæ¨¡å‹ç ”ç©¶é¡¹ç›®ï¼Œèšç„¦äº **Deep Interest Network (DIN)** åŠå…¶æ”¹è¿›æ–¹æ¡ˆã€‚

## ğŸ¯ é¡¹ç›®äº®ç‚¹

| ç‰¹ç‚¹ | è¯´æ˜ |
|------|------|
| ğŸ”¬ **ç³»ç»Ÿæ€§å®éªŒ** | 4ç»„å®éªŒï¼Œè¦†ç›–æ¨¡å‹å¯¹æ¯”ã€æ¶ˆèåˆ†æã€é«˜çº§æ”¹è¿› |
| ğŸ“Š **çœŸå®æ•°æ®éªŒè¯** | MovieLens 100K/1M æ•°æ®é›†ï¼ŒAUC æœ€é«˜è¾¾ **0.966** |
| ğŸ’¡ **åˆ›æ–°æ¢ç´¢** | è‡ªé€‚åº”æ—¶é—´è¡°å‡ã€å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒã€æ··åˆç²¾æ’ |
| ğŸ› ï¸ **å·¥ç¨‹å®Œå¤‡** | TensorBoard å¯è§†åŒ–ã€GPU åŠ é€Ÿã€æ¨¡å—åŒ–è®¾è®¡ |
| ğŸ“ **é¢è¯•å‹å¥½** | ä»£ç é€æ˜å¯è§£é‡Šï¼Œé€‚åˆæ·±å…¥è®²è§£ |

## ğŸ“ˆ æ ¸å¿ƒå®éªŒç»“æœ

### å®éªŒä¸€ï¼šæ¨¡å‹å¯¹æ¯” (ml-1m, seq_len=20)

| æ¨¡å‹ | Test AUC | HR@10 | NDCG@10 | å‚æ•°é‡ |
|------|----------|-------|---------|--------|
| **SASRec** | **0.9663** | **0.780** | **0.534** | 543K |
| GRU4Rec | 0.9608 | 0.780 | 0.534 | 467K |
| NARM | 0.9599 | 0.762 | 0.513 | 536K |
| **DIN** | 0.9584 | 0.758 | 0.509 | 460K |
| AvgPool | 0.9432 | 0.719 | 0.475 | 390K |

### å®éªŒä¸‰ï¼šæ¶ˆèå®éªŒ (ml-100k)

| å˜ä½“ | Test AUC | vs Base |
|------|----------|---------|
| DIN-Base | 0.8976 | baseline |
| **DIN-TimeDec** | **0.9120** | **+1.44%** |
| DIN-MultiHead | 0.8872 | -1.04% |
| DIN-Full | 0.8983 | +0.07% |

**å…³é”®å‘ç°**ï¼šæ—¶é—´è¡°å‡æ³¨æ„åŠ›å¸¦æ¥æ˜¾è‘—æå‡ï¼Œè€Œå¤šå¤´æ³¨æ„åŠ›åœ¨å°æ•°æ®é›†ä¸Šè¿‡æ‹Ÿåˆã€‚

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
DIN/
â”œâ”€â”€ ğŸ“Š å®éªŒè„šæœ¬
â”‚   â”œâ”€â”€ experiment1.py          # åºåˆ—é•¿åº¦ + æ¨¡å‹å¯¹æ¯”
â”‚   â”œâ”€â”€ experiment2.py          # æ–¹æ³•å¯¹æ¯” + æ··åˆç²¾æ’
â”‚   â”œâ”€â”€ experiment3.py          # æ¶ˆèå®éªŒ
â”‚   â””â”€â”€ experiment4.py          # é«˜çº§æ”¹è¿›ï¼ˆè‡ªé€‚åº”è¡°å‡+å¯¹æ¯”å­¦ä¹ ï¼‰
â”‚
â”œâ”€â”€ ğŸ§  æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ models.py               # DIN, GRU4Rec, SASRec, NARM, AvgPool
â”‚   â”œâ”€â”€ hybrid_ranker.py        # æ··åˆç²¾æ’æ¨¡å—
â”‚   â””â”€â”€ trainer.py              # è®­ç»ƒå™¨ + TensorBoard
â”‚
â”œâ”€â”€ ğŸ“¦ æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ data_loader.py          # æ•°æ®åŠ è½½ + åºåˆ—æ„å»º
â”‚   â””â”€â”€ feature_engineering.py  # ç‰¹å¾å·¥ç¨‹
â”‚
â”œâ”€â”€ ğŸ“„ æ–‡æ¡£
â”‚   â”œâ”€â”€ README.md               # é¡¹ç›®æ€»è§ˆï¼ˆæœ¬æ–‡ä»¶ï¼‰
â”‚   â”œâ”€â”€ FEATURES.md             # ç‰¹å¾å·¥ç¨‹è¯¦è§£
â”‚   â””â”€â”€ EXPERIMENTS.md          # å®éªŒè®¾è®¡è¯¦è§£
â”‚
â”œâ”€â”€ ğŸ“ è¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ results/                # CPU å®éªŒç»“æœ
â”‚   â””â”€â”€ results_gpu/            # GPU å®éªŒç»“æœ
â”‚
â””â”€â”€ ğŸ”§ å·¥å…·è„šæœ¬
    â”œâ”€â”€ run_experiments.py      # ä¸»å…¥å£
    â”œâ”€â”€ run_all_gpu.py          # GPU æ‰¹é‡è¿è¡Œ
    â””â”€â”€ requirements.txt        # ä¾èµ–åˆ—è¡¨
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd DIN

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æˆ–æ‰‹åŠ¨å®‰è£…
pip install torch numpy pandas matplotlib scikit-learn lightgbm tqdm tensorboard
```

### 2. è¿è¡Œå®éªŒ

```bash
# è¿è¡Œå…¨éƒ¨å®éªŒï¼ˆæ¨èï¼‰
python run_all_gpu.py --dataset ml-100k --experiments 1 2 3

# å•ç‹¬è¿è¡Œ
python experiment1.py   # æ¨¡å‹å¯¹æ¯”å®éªŒ
python experiment3.py   # æ¶ˆèå®éªŒ
python experiment4.py   # é«˜çº§æ”¹è¿›å®éªŒ

# æŒ‡å®šæ•°æ®é›†
python experiment4.py --dataset ml-1m --part adaptive
```

### 3. æŸ¥çœ‹ç»“æœ

```bash
# TensorBoard å¯è§†åŒ–
tensorboard --logdir runs/

# ç»“æœæ–‡ä»¶ä½äº results_gpu/ ç›®å½•
```

## ğŸ“š å®éªŒæ¦‚è§ˆ

| å®éªŒ | ç ”ç©¶é—®é¢˜ | å…³é”®å‘ç° |
|------|----------|----------|
| **å®éªŒä¸€** | åºåˆ—é•¿åº¦å¦‚ä½•å½±å“æ¨¡å‹ï¼Ÿ | 50-100 ä¸ºæœ€ä¼˜åŒºé—´ï¼Œè¿‡é•¿åè€Œä¸‹é™ |
| **å®éªŒäºŒ** | æ·±åº¦æ¨¡å‹ vs æ ‘æ¨¡å‹ï¼Ÿ | DIN ä¼˜äº LightGBM 2-3%ï¼Œæ··åˆç²¾æ’æœ‰é™æå‡ |
| **å®éªŒä¸‰** | DIN å„ç»„ä»¶è´¡çŒ®ï¼Ÿ | æ—¶é—´è¡°å‡ +1.44%ï¼Œå¤šå¤´æ³¨æ„åŠ›éœ€è°¨æ… |
| **å®éªŒå››** | é«˜çº§æ”¹è¿›æ–¹å‘ï¼Ÿ | è‡ªé€‚åº”è¡°å‡ã€å¯¹æ¯”å­¦ä¹ æœ‰æ½œåŠ› |

è¯¦è§ [EXPERIMENTS.md](EXPERIMENTS.md)

## ğŸ”¬ æŠ€æœ¯äº®ç‚¹

### 1. DIN æ ¸å¿ƒæ³¨æ„åŠ›æœºåˆ¶

```python
# æ³¨æ„åŠ›å…¬å¼: a(k, q) = softmax(MLP([k, q, k*q, k-q]))
attention_input = torch.cat([keys, query, keys * query, keys - query], dim=-1)
attention_scores = self.attention_mlp(attention_input)
```

### 2. æ—¶é—´è¡°å‡æ³¨æ„åŠ›ï¼ˆæ”¹è¿›ï¼‰

```python
# è¿‘æœŸè¡Œä¸ºæƒé‡æ›´é«˜
positions = torch.arange(seq_len)
time_weights = torch.exp(decay_rate * (positions - seq_len + 1))
attention_scores = base_scores * time_weights
```

### 3. è‡ªé€‚åº”è¡°å‡ï¼ˆåˆ›æ–°ï¼Œå®éªŒå››ï¼‰

```python
# è¡°å‡ç‡ä½œä¸ºå¯å­¦ä¹ å‚æ•°
self.decay_rate = nn.Parameter(torch.tensor(0.1))
```

### 4. å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒï¼ˆåˆ›æ–°ï¼Œå®éªŒå››ï¼‰

```python
# InfoNCE æŸå¤± + åºåˆ—å¢å¼º
z1 = encoder(augment(seq, 'crop'))
z2 = encoder(augment(seq, 'mask'))
loss = InfoNCE(z1, z2, temperature=0.1)
```

## ğŸ“Š ç‰¹å¾å·¥ç¨‹

è¯¦è§ [FEATURES.md](FEATURES.md)

| ç‰¹å¾ç±»å‹ | ç¤ºä¾‹ | ç»´åº¦ |
|----------|------|------|
| ç”¨æˆ·ç”»åƒ | age_bucket, gender, occupation | 3 |
| ç‰©å“å±æ€§ | genre, year_bucket, popularity | 3 |
| åºåˆ—ç‰¹å¾ | history_genres, history_years | 2Ã—L |
| æ—¶é—´ä¸Šä¸‹æ–‡ | hour_bucket, day_of_week, is_weekend | 3 |
| ç»Ÿè®¡ç‰¹å¾ | user_activity, item_popularity | 2 |

## ğŸ–¥ï¸ ç¡¬ä»¶è¦æ±‚

| é…ç½® | æœ€ä½è¦æ±‚ | æ¨èé…ç½® |
|------|----------|----------|
| GPU | GTX 1060 6GB | RTX 3080 Ti |
| RAM | 8GB | 16GB+ |
| å­˜å‚¨ | 1GB | 5GB |

**å®æµ‹è¿è¡Œæ—¶é—´**ï¼ˆRTX 3080 Tiï¼‰ï¼š

| å®éªŒ | ml-100k | ml-1m |
|------|---------|-------|
| å®éªŒä¸€ï¼ˆ20ç»„ï¼‰ | 2.5 å°æ—¶ | 9.4 å°æ—¶ |
| å®éªŒä¸‰ï¼ˆ5ç»„ï¼‰ | 27 åˆ†é’Ÿ | 2 å°æ—¶ |

## ğŸ“– å‚è€ƒè®ºæ–‡

1. **[DIN]** Zhou et al. "Deep Interest Network for Click-Through Rate Prediction" (KDD 2018)
2. **[GRU4Rec]** Hidasi et al. "Session-based Recommendations with RNNs" (ICLR 2016)
3. **[SASRec]** Kang & McAuley. "Self-Attentive Sequential Recommendation" (ICDM 2018)
4. **[NARM]** Li et al. "Neural Attentive Session-based Recommendation" (CIKM 2017)
5. **[CL4SRec]** Xie et al. "Contrastive Learning for Sequential Recommendation" (ICDE 2022)

## ğŸ¤ è‡´è°¢

- MovieLens æ•°æ®é›†ç”± GroupLens Research æä¾›
- é¡¹ç›®çµæ„Ÿæ¥æºäºé˜¿é‡Œå·´å·´ DIN è®ºæ–‡åŠå·¥ä¸šå®è·µ

## ğŸ“„ License

MIT License - å¯è‡ªç”±ä½¿ç”¨äºå­¦ä¹ å’Œç ”ç©¶ç›®çš„

---

<p align="center">
  <b>å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿ â­ Star</b>
</p>
