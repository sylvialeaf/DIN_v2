#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆè®­ç»ƒå™¨

æ”¯æŒä¸°å¯Œç‰¹å¾çš„æ¨¡å‹è®­ç»ƒã€‚
æ”¯æŒ CTR æŒ‡æ ‡ï¼ˆAUC, LogLossï¼‰å’Œ Top-K æ¨èæŒ‡æ ‡ï¼ˆRecall@K, NDCG@K, HR@K, MRRï¼‰ã€‚
æ”¯æŒ TensorBoard å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚
æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ (AMP) åŠ é€Ÿã€‚
"""

import torch
import torch.nn as nn
from torch.optim import Adam
from sklearn.metrics import roc_auc_score, log_loss
import numpy as np
from tqdm import tqdm
import time
import os
from datetime import datetime

# æ··åˆç²¾åº¦è®­ç»ƒæ”¯æŒ (PyTorch 1.6+)
try:
    from torch.cuda.amp import GradScaler, autocast
    HAS_AMP = True
except ImportError:
    HAS_AMP = False

# TensorBoard æ”¯æŒ
try:
    from torch.utils.tensorboard import SummaryWriter
    HAS_TENSORBOARD = True
except ImportError:
    HAS_TENSORBOARD = False
    print("è­¦å‘Š: TensorBoard æœªå®‰è£…ï¼Œå¯è§†åŒ–åŠŸèƒ½ä¸å¯ç”¨ã€‚å®‰è£…: pip install tensorboard")


# ========================================
# Top-K è¯„ä¼°æŒ‡æ ‡
# ========================================

def hit_at_k(ranked_items, ground_truth, k):
    """
    Hit Rate @ K
    å¦‚æœ ground_truth åœ¨ top-k ä¸­ï¼Œè¿”å› 1ï¼Œå¦åˆ™è¿”å› 0
    """
    return 1.0 if ground_truth in ranked_items[:k] else 0.0


def recall_at_k(ranked_items, ground_truth, k):
    """
    Recall @ K
    å¯¹äºå•ä¸ª ground truthï¼Œç­‰åŒäº Hit Rate
    """
    return hit_at_k(ranked_items, ground_truth, k)


def ndcg_at_k(ranked_items, ground_truth, k):
    """
    NDCG @ K (Normalized Discounted Cumulative Gain)
    """
    for i, item in enumerate(ranked_items[:k]):
        if item == ground_truth:
            # DCG = 1 / log2(rank + 1)ï¼ŒIDCG = 1 / log2(2) = 1
            return 1.0 / np.log2(i + 2)  # +2 å› ä¸º rank ä» 1 å¼€å§‹
    return 0.0


def mrr_at_k(ranked_items, ground_truth, k):
    """
    MRR @ K (Mean Reciprocal Rank)
    """
    for i, item in enumerate(ranked_items[:k]):
        if item == ground_truth:
            return 1.0 / (i + 1)
    return 0.0


def precision_at_k(ranked_items, ground_truth, k):
    """
    Precision @ K
    å¯¹äºå•ä¸ª ground truth: å‘½ä¸­åˆ™ä¸º 1/kï¼Œå¦åˆ™ä¸º 0
    """
    if ground_truth in ranked_items[:k]:
        return 1.0 / k
    return 0.0


class RichTrainer:
    """
    å¢å¼ºç‰ˆè®­ç»ƒå™¨
    
    æ”¯æŒ batch å­—å…¸å½¢å¼çš„è¾“å…¥ã€‚
    æ”¯æŒå¤š GPU DistributedDataParallel (DDP) åŠ é€Ÿã€‚
    æ”¯æŒ TensorBoard å¯è§†åŒ–ã€‚
    """
    
    def __init__(
        self,
        model,
        device='cpu',
        learning_rate=1e-3,
        weight_decay=1e-5,
        use_multi_gpu=False,  # æ˜¯å¦ä½¿ç”¨å¤š GPU (DataParallel)
        use_ddp=False,  # æ˜¯å¦ä½¿ç”¨ DDPï¼ˆæ›´é«˜æ•ˆï¼‰
        local_rank=-1,  # DDP çš„ local rank
        use_amp=True,  # æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        use_tensorboard=True,  # æ˜¯å¦ä½¿ç”¨ TensorBoard
        log_dir='./runs',  # TensorBoard æ—¥å¿—ç›®å½•
        experiment_name=None  # å®éªŒåç§°
    ):
        self.device = device
        self.use_ddp = use_ddp
        self.local_rank = local_rank
        self.is_main_process = (local_rank <= 0)  # rank 0 æˆ–éDDPæ¨¡å¼
        self.use_multi_gpu = use_multi_gpu and torch.cuda.device_count() > 1 and not use_ddp
        self.learning_rate = learning_rate
        
        # æ··åˆç²¾åº¦è®­ç»ƒ (AMP) - ä»…åœ¨ GPU ä¸Šå¯ç”¨
        # æ”¯æŒ 'cuda', 'cuda:0', 'cuda:1' ç­‰æ ¼å¼
        is_cuda_device = str(device).startswith('cuda') or device == 'cuda'
        self.use_amp = use_amp and HAS_AMP and is_cuda_device
        if self.use_amp and self.is_main_process:
            self.scaler = GradScaler()
            print("âš¡ æ··åˆç²¾åº¦è®­ç»ƒ (AMP) å·²å¯ç”¨")
        elif self.use_amp:
            self.scaler = GradScaler()
        else:
            self.scaler = None
        
        # å°†æ¨¡å‹ç§»åˆ°è®¾å¤‡
        model = model.to(device)
        
        # DDP æ”¯æŒï¼ˆä¼˜å…ˆäº DataParallelï¼‰
        if self.use_ddp:
            from torch.nn.parallel import DistributedDataParallel as DDP
            model = DDP(model, device_ids=[local_rank], output_device=local_rank)
            if self.is_main_process:
                print(f"ğŸš€ ä½¿ç”¨ DistributedDataParallel (DDP): GPU {local_rank}")
        # DataParallel æ”¯æŒï¼ˆå¤‡é€‰ï¼‰
        elif self.use_multi_gpu:
            if self.is_main_process:
                print(f"ğŸ”¥ ä½¿ç”¨ DataParallel: {torch.cuda.device_count()} GPUs")
            model = nn.DataParallel(model)
        
        self.model = model
        
        self.criterion = nn.BCEWithLogitsLoss()
        self.optimizer = Adam(
            model.parameters(), 
            lr=learning_rate,
            weight_decay=weight_decay
        )
        
        # TensorBoard è®¾ç½®ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
        self.use_tensorboard = use_tensorboard and HAS_TENSORBOARD and self.is_main_process
        self.writer = None
        self.global_step = 0
        self._writer_closed = False  # é˜²æ­¢é‡å¤å…³é—­
        
        if self.use_tensorboard:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            exp_name = experiment_name or "default"
            self.log_dir = os.path.join(log_dir, f"{exp_name}_{timestamp}")
            os.makedirs(self.log_dir, exist_ok=True)
            self.writer = SummaryWriter(self.log_dir)
            print(f"ğŸ“Š TensorBoard å·²å¯ç”¨")
            print(f"   æ—¥å¿—ç›®å½•: {self.log_dir}")
            print(f"   å¯åŠ¨å‘½ä»¤: tensorboard --logdir {log_dir}")
    
    def close(self):
        """å…³é—­ TensorBoard writerï¼ˆæ˜¾å¼è°ƒç”¨ï¼‰"""
        if self.writer is not None and not self._writer_closed:
            self.writer.close()
            self._writer_closed = True
    
    def __del__(self):
        """ææ„æ—¶ç¡®ä¿ writer è¢«å…³é—­"""
        self.close()
    
    @property
    def raw_model(self):
        """è·å–åŸå§‹æ¨¡å‹ï¼ˆç”¨äºè®¿é—®æ¨¡å‹å±æ€§æˆ–ä¿å­˜ï¼‰"""
        if (self.use_multi_gpu or self.use_ddp) and hasattr(self.model, 'module'):
            return self.model.module
        return self.model
    
    def _move_batch_to_device(self, batch):
        """å°† batch ç§»åŠ¨åˆ°è®¾å¤‡"""
        return {k: v.to(self.device, non_blocking=True) for k, v in batch.items()}
    
    def train_epoch(self, train_loader, show_progress=True):
        """è®­ç»ƒä¸€ä¸ª epochï¼ˆæ”¯æŒæ··åˆç²¾åº¦ï¼‰"""
        self.model.train()
        total_loss = 0
        
        # ä»…ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦æ¡
        show = show_progress and self.is_main_process
        iterator = tqdm(train_loader, desc='Training') if show else train_loader
        
        for batch in iterator:
            batch = self._move_batch_to_device(batch)
            
            self.optimizer.zero_grad()
            
            # æ··åˆç²¾åº¦è®­ç»ƒ
            if self.use_amp:
                with autocast():
                    logits = self.model(batch)
                    loss = self.criterion(logits, batch['label'])
                
                self.scaler.scale(loss).backward()
                self.scaler.unscale_(self.optimizer)
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                logits = self.model(batch)
                loss = self.criterion(logits, batch['label'])
                
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)
                self.optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / len(train_loader)
    
    def evaluate(self, data_loader, show_progress=False):
        """è¯„ä¼°æ¨¡å‹ï¼ˆæ”¯æŒæ··åˆç²¾åº¦ï¼‰"""
        self.model.eval()
        
        all_preds = []
        all_labels = []
        
        iterator = tqdm(data_loader, desc='Evaluating') if show_progress else data_loader
        
        with torch.no_grad():
            for batch in iterator:
                batch = self._move_batch_to_device(batch)
                
                # è¯„ä¼°æ—¶ä¹Ÿä½¿ç”¨ AMP åŠ é€Ÿ
                if self.use_amp:
                    with autocast():
                        logits = self.model(batch)
                else:
                    logits = self.model(batch)
                
                preds = torch.sigmoid(logits).cpu().numpy()
                labels = batch['label'].cpu().numpy()
                
                all_preds.extend(preds)
                all_labels.extend(labels)
        
        all_preds = np.array(all_preds)
        all_labels = np.array(all_labels)
        
        auc = roc_auc_score(all_labels, all_preds)
        logloss = log_loss(all_labels, np.clip(all_preds, 1e-7, 1-1e-7))
        
        return {
            'auc': auc,
            'logloss': logloss
        }
    
    def fit(
        self,
        train_loader,
        valid_loader,
        epochs=20,
        early_stopping_patience=5,
        show_progress=True
    ):
        """è®­ç»ƒæ¨¡å‹ï¼ˆæ”¯æŒ TensorBoard å¯è§†åŒ–ï¼‰"""
        best_valid_auc = 0
        patience_counter = 0
        best_model_state = None
        
        # è®°å½•è¶…å‚æ•°åˆ° TensorBoard
        if self.use_tensorboard and self.writer is not None:
            self.writer.add_text('Hyperparameters', 
                f'learning_rate={self.learning_rate}, epochs={epochs}, '
                f'early_stopping_patience={early_stopping_patience}')
        
        for epoch in range(epochs):
            train_loss = self.train_epoch(train_loader, show_progress)
            valid_metrics = self.evaluate(valid_loader)
            
            print(f"Epoch {epoch+1}/{epochs} - "
                  f"Loss: {train_loss:.4f} - "
                  f"Valid AUC: {valid_metrics['auc']:.4f} - "
                  f"Valid LogLoss: {valid_metrics['logloss']:.4f}")
            
            # TensorBoard è®°å½•
            if self.use_tensorboard and self.writer is not None:
                self.writer.add_scalar('Loss/train', train_loss, epoch)
                self.writer.add_scalar('Metrics/valid_auc', valid_metrics['auc'], epoch)
                self.writer.add_scalar('Metrics/valid_logloss', valid_metrics['logloss'], epoch)
                self.writer.add_scalar('Learning_rate', 
                    self.optimizer.param_groups[0]['lr'], epoch)
            
            if valid_metrics['auc'] > best_valid_auc:
                best_valid_auc = valid_metrics['auc']
                best_model_state = self.model.state_dict().copy()
                patience_counter = 0
                
                # è®°å½•æœ€ä½³æŒ‡æ ‡
                if self.use_tensorboard and self.writer is not None:
                    self.writer.add_scalar('Metrics/best_valid_auc', best_valid_auc, epoch)
            else:
                patience_counter += 1
                if patience_counter >= early_stopping_patience:
                    print(f"Early stopping at epoch {epoch+1}")
                    if self.use_tensorboard and self.writer is not None:
                        self.writer.add_text('Training', f'Early stopped at epoch {epoch+1}')
                    break
        
        if best_model_state is not None:
            self.model.load_state_dict(best_model_state)
        
        # å…³é—­ TensorBoard writerï¼ˆä½¿ç”¨ close æ–¹æ³•é¿å…é‡å¤å…³é—­ï¼‰
        if self.use_tensorboard and self.writer is not None and not self._writer_closed:
            self.writer.add_hparams(
                {'lr': self.learning_rate, 'epochs': epoch + 1},
                {'hparam/best_valid_auc': best_valid_auc}
            )
            self.close()
            print(f"âœ“ TensorBoard æ—¥å¿—å·²ä¿å­˜åˆ°: {self.log_dir}")
        
        return {
            'best_valid_auc': best_valid_auc,
            'final_epoch': epoch + 1
        }
    
    def evaluate_topk(
        self,
        eval_data,
        feature_processor,
        interaction_extractor,
        max_seq_length,
        ks=[5, 10, 20],
        show_progress=True,
        batch_size=256
    ):
        """
        Top-K æ¨èè¯„ä¼°ï¼ˆæ‰¹é‡ä¼˜åŒ–ç‰ˆï¼‰
        
        Args:
            eval_data: list of dictï¼Œæ¥è‡ª get_topk_eval_data
            feature_processor: ç‰¹å¾å¤„ç†å™¨
            interaction_extractor: äº¤äº’ç‰¹å¾æå–å™¨
            max_seq_length: æœ€å¤§åºåˆ—é•¿åº¦
            ks: è¯„ä¼°çš„ K å€¼åˆ—è¡¨
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            batch_size: æ‰¹é‡è¯„ä¼°çš„ç”¨æˆ·æ•°
        
        Returns:
            dict: å„æŒ‡æ ‡åœ¨ä¸åŒ K ä¸‹çš„å€¼
        """
        from data_loader import build_topk_batch_multi
        
        self.model.eval()
        
        # åˆå§‹åŒ–æŒ‡æ ‡ç´¯åŠ å™¨
        all_hr = {k: [] for k in ks}
        all_ndcg = {k: [] for k in ks}
        all_mrr = {k: [] for k in ks}
        
        # åˆ†æ‰¹å¤„ç†
        num_users = len(eval_data)
        num_batches = (num_users + batch_size - 1) // batch_size
        
        iterator = range(num_batches)
        if show_progress:
            iterator = tqdm(iterator, desc='Top-K Eval')
        
        with torch.no_grad():
            for batch_idx in iterator:
                start_idx = batch_idx * batch_size
                end_idx = min(start_idx + batch_size, num_users)
                batch_eval_data = eval_data[start_idx:end_idx]
                
                # æ‰¹é‡æ„å»ºå¹¶è¯„ä¼°
                for eval_item in batch_eval_data:
                    # æ„å»ºå•ç”¨æˆ·çš„å€™é€‰ batch
                    batch = build_topk_batch_multi(
                        eval_item, feature_processor, interaction_extractor,
                        max_seq_length, self.device
                    )
                    
                    # é¢„æµ‹åˆ†æ•°
                    logits = self.model(batch)
                    scores = torch.sigmoid(logits).cpu().numpy()
                    
                    # æ’åº
                    candidates = eval_item['candidates']
                    ground_truth = eval_item['ground_truth']
                    sorted_indices = np.argsort(-scores)
                    ranked_items = [candidates[i] for i in sorted_indices]
                    
                    # è®¡ç®—æŒ‡æ ‡
                    for k in ks:
                        all_hr[k].append(hit_at_k(ranked_items, ground_truth, k))
                        all_ndcg[k].append(ndcg_at_k(ranked_items, ground_truth, k))
                        all_mrr[k].append(mrr_at_k(ranked_items, ground_truth, k))
        
        # è®¡ç®—å¹³å‡å€¼
        results = {}
        for k in ks:
            results[f'HR@{k}'] = np.mean(all_hr[k])
            results[f'Recall@{k}'] = np.mean(all_hr[k])  # å• GT ç­‰äº HR
            results[f'NDCG@{k}'] = np.mean(all_ndcg[k])
            results[f'MRR@{k}'] = np.mean(all_mrr[k])
            results[f'Precision@{k}'] = np.mean(all_hr[k]) / k
        
        return results


def measure_inference_speed_rich(model, data_loader, device='cpu', warmup_batches=5, measure_batches=20):
    """
    æµ‹é‡æ¨ç†é€Ÿåº¦ï¼ˆQPSï¼‰
    
    é€‚ç”¨äº batch å­—å…¸è¾“å…¥çš„æ¨¡å‹ã€‚
    """
    model.eval()
    model = model.to(device)
    
    sample_batch = next(iter(data_loader))
    batch_size = sample_batch['user_id'].shape[0]
    
    # Warmup
    with torch.no_grad():
        for i, batch in enumerate(data_loader):
            if i >= warmup_batches:
                break
            batch = {k: v.to(device) for k, v in batch.items()}
            _ = model(batch)
    
    # æµ‹é‡
    total_samples = 0
    start_time = time.time()
    
    with torch.no_grad():
        for i, batch in enumerate(data_loader):
            if i >= measure_batches:
                break
            batch = {k: v.to(device) for k, v in batch.items()}
            _ = model(batch)
            total_samples += batch['user_id'].shape[0]
    
    elapsed = time.time() - start_time
    qps = total_samples / elapsed if elapsed > 0 else 0
    
    return {
        'qps': qps,
        'total_samples': total_samples,
        'elapsed_time': elapsed
    }


if __name__ == "__main__":
    print("æµ‹è¯•å¢å¼ºç‰ˆè®­ç»ƒå™¨...")
    
    from data_loader import get_rich_dataloaders
    from models import DINRichLite
    
    train_loader, valid_loader, test_loader, info, fp = get_rich_dataloaders(
        data_dir='./data',
        dataset_name='ml-100k',
        max_seq_length=50,
        batch_size=256
    )
    
    model = DINRichLite(
        num_items=info['num_items'],
        num_users=info['num_users'],
        feature_dims=info['feature_dims'],
        embedding_dim=64
    )
    
    trainer = RichTrainer(model=model, device='cpu')
    
    # å¿«é€Ÿæµ‹è¯•
    result = trainer.fit(
        train_loader=train_loader,
        valid_loader=valid_loader,
        epochs=2,
        show_progress=True
    )
    
    print(f"\nè®­ç»ƒç»“æœ: {result}")
    
    test_metrics = trainer.evaluate(test_loader)
    print(f"æµ‹è¯•ç»“æœ: {test_metrics}")
