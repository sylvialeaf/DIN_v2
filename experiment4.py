#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å®éªŒå››ï¼šDIN é«˜çº§æ”¹è¿›å®éªŒ

ç ”ç©¶æ–¹å‘ï¼š
1. è‡ªé€‚åº”æ—¶é—´è¡°å‡ï¼ˆAdaptive Time Decayï¼‰
   - å°†å›ºå®šçš„ decay_rate æ”¹ä¸ºå¯å­¦ä¹ å‚æ•°
   - æ¢ç´¢ç”¨æˆ·çº§åˆ«çš„ä¸ªæ€§åŒ–è¡°å‡

2. å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒï¼ˆContrastive Learning Pre-trainingï¼‰
   - ä½¿ç”¨ SimCLR/InfoNCE é£æ ¼çš„å¯¹æ¯”æŸå¤±
   - æ•°æ®å¢å¼ºï¼šåºåˆ—è£å‰ªã€ç‰©å“æ›¿æ¢ã€æ©ç 
   - ä¸¤é˜¶æ®µè®­ç»ƒï¼šé¢„è®­ç»ƒ â†’ å¾®è°ƒ

åˆ›æ–°ç‚¹ï¼š
- é¦–æ¬¡åœ¨ DIN æ¡†æ¶ä¸‹æ¢ç´¢è‡ªé€‚åº”è¡°å‡
- å¯¹æ¯”å­¦ä¹ è§£å†³å†·å¯åŠ¨é—®é¢˜
- æ¶ˆèå®éªŒéªŒè¯å„ç»„ä»¶è´¡çŒ®

è¾“å‡º:
- results/experiment4_adaptive_decay.csv
- results/experiment4_contrastive.csv
- results/experiment4_combined.csv
"""

import os
import sys
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import json
import time
import copy

from data_loader import get_rich_dataloaders, get_topk_eval_data, build_topk_batch_multi
from trainer import RichTrainer, measure_inference_speed_rich


# ========================================
# Top-K è¯„ä¼°æŒ‡æ ‡å‡½æ•°ï¼ˆä¸ run_ddp.py ä¸€è‡´ï¼‰
# ========================================

def hit_at_k(ranked_items, ground_truth, k):
    """Hit Rate @ K"""
    return 1.0 if ground_truth in ranked_items[:k] else 0.0


def ndcg_at_k(ranked_items, ground_truth, k):
    """NDCG @ K"""
    for i, item in enumerate(ranked_items[:k]):
        if item == ground_truth:
            return 1.0 / np.log2(i + 2)
    return 0.0


def mrr_at_k(ranked_items, ground_truth, k):
    """MRR @ K"""
    for i, item in enumerate(ranked_items[:k]):
        if item == ground_truth:
            return 1.0 / (i + 1)
    return 0.0


def precision_at_k(ranked_items, ground_truth, k):
    """Precision @ K"""
    hits = 1 if ground_truth in ranked_items[:k] else 0
    return hits / k


def evaluate_topk_metrics(model, eval_data, feature_processor, interaction_extractor, 
                          max_seq_length, device, ks=[5, 10, 20]):
    """
    ç»Ÿä¸€çš„ Top-K è¯„ä¼°å‡½æ•°
    
    ä¸ run_ddp.py ä¸­çš„ SimpleDDPTrainer.evaluate_topk ä¿æŒä¸€è‡´
    """
    model.eval()
    
    all_hr = {k: [] for k in ks}
    all_ndcg = {k: [] for k in ks}
    all_mrr = {k: [] for k in ks}
    all_precision = {k: [] for k in ks}
    
    with torch.no_grad():
        for eval_item in eval_data:
            batch = build_topk_batch_multi(
                eval_item, feature_processor, interaction_extractor,
                max_seq_length, device
            )
            
            logits = model(batch)
            scores = torch.sigmoid(logits).cpu().numpy()
            
            candidates = eval_item['candidates']
            ground_truth = eval_item['ground_truth']
            sorted_indices = np.argsort(-scores)
            ranked_items = [candidates[i] for i in sorted_indices]
            
            for k in ks:
                all_hr[k].append(hit_at_k(ranked_items, ground_truth, k))
                all_ndcg[k].append(ndcg_at_k(ranked_items, ground_truth, k))
                all_mrr[k].append(mrr_at_k(ranked_items, ground_truth, k))
                all_precision[k].append(precision_at_k(ranked_items, ground_truth, k))
    
    results = {}
    for k in ks:
        results[f'HR@{k}'] = np.mean(all_hr[k])
        results[f'Recall@{k}'] = np.mean(all_hr[k])  # å• GT ç­‰äº HR
        results[f'NDCG@{k}'] = np.mean(all_ndcg[k])
        results[f'MRR@{k}'] = np.mean(all_mrr[k])
        results[f'Precision@{k}'] = np.mean(all_precision[k])
    
    return results


# ========================================
# Part 1: è‡ªé€‚åº”æ—¶é—´è¡°å‡æ³¨æ„åŠ›
# ========================================

class AdaptiveTimeDecayAttention(nn.Module):
    """
    è‡ªé€‚åº”æ—¶é—´è¡°å‡æ³¨æ„åŠ›æœºåˆ¶
    
    åˆ›æ–°ç‚¹ï¼š
    1. decay_rate ä½œä¸ºå¯å­¦ä¹ å‚æ•°
    2. æ”¯æŒå…¨å±€å­¦ä¹ æˆ–ç”¨æˆ·çº§åˆ«ä¸ªæ€§åŒ–
    
    å…¬å¼: score_i = base_score_i * exp(decay_rate * (pos_i - L + 1))
    """
    
    def __init__(
        self, 
        input_dim, 
        hidden_dims=[64, 32], 
        init_decay=0.1,
        learnable_decay=True,
        per_user_decay=False,
        num_users=None
    ):
        super(AdaptiveTimeDecayAttention, self).__init__()
        
        self.learnable_decay = learnable_decay
        self.per_user_decay = per_user_decay
        
        # åŸºç¡€æ³¨æ„åŠ› MLP
        mlp_input = 4 * input_dim
        layers = []
        prev_dim = mlp_input
        for hidden_dim in hidden_dims:
            layers.append(nn.Linear(prev_dim, hidden_dim))
            layers.append(nn.PReLU())
            prev_dim = hidden_dim
        layers.append(nn.Linear(prev_dim, 1))
        self.attention_mlp = nn.Sequential(*layers)
        
        # æ—¶é—´è¡°å‡å‚æ•°
        if learnable_decay:
            if per_user_decay and num_users is not None:
                # ç”¨æˆ·çº§åˆ«çš„ä¸ªæ€§åŒ–è¡°å‡ï¼ˆé«˜çº§ç‰ˆæœ¬ï¼‰
                self.decay_rate = nn.Embedding(num_users + 1, 1)
                nn.init.constant_(self.decay_rate.weight, init_decay)
            else:
                # å…¨å±€å¯å­¦ä¹ è¡°å‡
                self.decay_rate = nn.Parameter(torch.tensor(init_decay))
        else:
            # å›ºå®šè¡°å‡ï¼ˆbaselineï¼‰
            self.register_buffer('decay_rate', torch.tensor(init_decay))
    
    def forward(self, query, keys, keys_mask=None, user_ids=None):
        """
        Args:
            query: [B, D] ç›®æ ‡ç‰©å“åµŒå…¥
            keys: [B, L, D] å†å²åºåˆ—åµŒå…¥
            keys_mask: [B, L] æœ‰æ•ˆä½ç½®æ©ç 
            user_ids: [B] ç”¨æˆ·IDï¼ˆç”¨äºä¸ªæ€§åŒ–è¡°å‡ï¼‰
        """
        batch_size, seq_len, dim = keys.shape
        
        # 1. è®¡ç®—åŸºç¡€æ³¨æ„åŠ›åˆ†æ•°
        query_expanded = query.unsqueeze(1).expand(-1, seq_len, -1)
        attention_input = torch.cat([
            keys, query_expanded,
            keys * query_expanded,
            keys - query_expanded
        ], dim=-1)
        base_scores = self.attention_mlp(attention_input).squeeze(-1)  # [B, L]
        
        # 2. è®¡ç®—æ—¶é—´è¡°å‡æƒé‡
        positions = torch.arange(seq_len, device=keys.device).float()
        
        if self.learnable_decay:
            if self.per_user_decay and user_ids is not None:
                # ç”¨æˆ·çº§åˆ«è¡°å‡
                user_decay = self.decay_rate(user_ids).squeeze(-1)  # [B]
                time_weights = torch.exp(
                    user_decay.unsqueeze(1) * (positions - seq_len + 1).unsqueeze(0)
                )
            else:
                # å…¨å±€è¡°å‡
                time_weights = torch.exp(self.decay_rate * (positions - seq_len + 1))
                time_weights = time_weights.unsqueeze(0)  # [1, L]
        else:
            time_weights = torch.exp(self.decay_rate * (positions - seq_len + 1))
            time_weights = time_weights.unsqueeze(0)
        
        # 3. èåˆæ—¶é—´è¡°å‡
        attention_scores = base_scores * time_weights
        
        # 4. Mask å’Œ Softmaxï¼ˆä½¿ç”¨ float('-inf') ä¸ models.py ä¿æŒä¸€è‡´ï¼‰
        if keys_mask is not None:
            attention_scores = attention_scores.masked_fill(~keys_mask.bool(), float('-inf'))
        
        attention_weights = F.softmax(attention_scores, dim=-1)
        
        # å¤„ç†å¯èƒ½çš„ NaNï¼ˆå…¨ padding æƒ…å†µï¼‰
        attention_weights = torch.where(
            torch.isnan(attention_weights),
            torch.zeros_like(attention_weights),
            attention_weights
        )
        
        # 5. åŠ æƒæ±‚å’Œ
        weighted_sum = torch.sum(attention_weights.unsqueeze(-1) * keys, dim=1)
        
        return weighted_sum, attention_weights
    
    def get_decay_rate(self):
        """è·å–å½“å‰è¡°å‡ç‡ï¼ˆç”¨äºç›‘æ§å’Œå¯è§†åŒ–ï¼‰"""
        if self.learnable_decay and not self.per_user_decay:
            return self.decay_rate.item()
        return None


class DINAdaptiveDecay(nn.Module):
    """
    å¸¦è‡ªé€‚åº”æ—¶é—´è¡°å‡çš„ DIN æ¨¡å‹
    """
    
    def __init__(
        self,
        num_items,
        num_users,
        feature_dims,
        embedding_dim=64,
        feature_embedding_dim=16,
        mlp_hidden_dims=[256, 128, 64],
        dropout_rate=0.2,
        init_decay=0.1,
        learnable_decay=True,
        per_user_decay=False
    ):
        super(DINAdaptiveDecay, self).__init__()
        
        self.embedding_dim = embedding_dim
        self.feature_embedding_dim = feature_embedding_dim
        
        # åµŒå…¥å±‚
        self.item_embedding = nn.Embedding(num_items + 1, embedding_dim, padding_idx=0)
        self.user_embedding = nn.Embedding(num_users + 1, feature_embedding_dim)
        self.genre_embedding = nn.Embedding(
            feature_dims.get('primary_genre', 20) + 1, 
            feature_embedding_dim, 
            padding_idx=0
        )
        self.year_embedding = nn.Embedding(
            feature_dims.get('year_bucket', 8) + 1, 
            feature_embedding_dim, 
            padding_idx=0
        )
        self.age_embedding = nn.Embedding(
            feature_dims.get('age_bucket', 10) + 1, 
            feature_embedding_dim
        )
        self.gender_embedding = nn.Embedding(3, feature_embedding_dim)
        self.occupation_embedding = nn.Embedding(
            feature_dims.get('occupation', 25) + 1, 
            feature_embedding_dim
        )
        
        # åºåˆ—ç‰¹å¾ç»´åº¦
        self.seq_feature_dim = embedding_dim + 2 * feature_embedding_dim
        
        # è‡ªé€‚åº”æ—¶é—´è¡°å‡æ³¨æ„åŠ›
        self.attention = AdaptiveTimeDecayAttention(
            input_dim=self.seq_feature_dim,
            hidden_dims=[64, 32],
            init_decay=init_decay,
            learnable_decay=learnable_decay,
            per_user_decay=per_user_decay,
            num_users=num_users if per_user_decay else None
        )
        
        # MLP
        mlp_input_dim = (
            self.seq_feature_dim +  # ç”¨æˆ·å…´è¶£
            self.seq_feature_dim +  # ç›®æ ‡ç‰©å“
            feature_embedding_dim +  # ç”¨æˆ·åµŒå…¥
            feature_embedding_dim * 3  # å¹´é¾„ + æ€§åˆ« + èŒä¸š
        )
        
        mlp_layers = []
        prev_dim = mlp_input_dim
        for hidden_dim in mlp_hidden_dims:
            mlp_layers.append(nn.Linear(prev_dim, hidden_dim))
            mlp_layers.append(nn.BatchNorm1d(hidden_dim))
            mlp_layers.append(nn.PReLU())
            mlp_layers.append(nn.Dropout(dropout_rate))
            prev_dim = hidden_dim
        mlp_layers.append(nn.Linear(prev_dim, 1))
        
        self.mlp = nn.Sequential(*mlp_layers)
        
        self._init_weights()
    
    def _init_weights(self):
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
            elif isinstance(module, nn.Embedding):
                nn.init.normal_(module.weight, mean=0, std=0.01)
    
    def forward(self, batch):
        # å†å²åºåˆ—åµŒå…¥
        seq_item_emb = self.item_embedding(batch['item_seq'])
        seq_genre_emb = self.genre_embedding(batch['history_genres'])
        seq_year_emb = self.year_embedding(batch['history_years'])
        seq_combined = torch.cat([seq_item_emb, seq_genre_emb, seq_year_emb], dim=-1)
        
        # ç›®æ ‡ç‰©å“åµŒå…¥
        target_item_emb = self.item_embedding(batch['target_item'])
        target_genre_emb = self.genre_embedding(batch['item_genre'])
        target_year_emb = self.year_embedding(batch['item_year'])
        target_combined = torch.cat([target_item_emb, target_genre_emb, target_year_emb], dim=-1)
        
        # è‡ªé€‚åº”æ—¶é—´è¡°å‡æ³¨æ„åŠ›
        user_interest, _ = self.attention(
            target_combined, 
            seq_combined, 
            batch['item_seq_mask'],
            batch.get('user_id', None)
        )
        
        # ç”¨æˆ·ç‰¹å¾
        user_emb = self.user_embedding(batch['user_id'])
        age_emb = self.age_embedding(batch['user_age'])
        gender_emb = self.gender_embedding(batch['user_gender'])
        occupation_emb = self.occupation_embedding(batch['user_occupation'])
        
        # æ‹¼æ¥å¹¶é¢„æµ‹
        features = torch.cat([
            user_interest, target_combined,
            user_emb, age_emb, gender_emb, occupation_emb
        ], dim=-1)
        
        return self.mlp(features).squeeze(-1)
    
    def get_decay_rate(self):
        """è·å–å½“å‰å­¦ä¹ åˆ°çš„è¡°å‡ç‡"""
        return self.attention.get_decay_rate()


# ========================================
# Part 2: å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒ
# ========================================

class SequenceAugmentation:
    """
    åºåˆ—æ•°æ®å¢å¼ºå™¨
    
    æ”¯æŒå¤šç§å¢å¼ºç­–ç•¥ï¼š
    1. éšæœºè£å‰ªï¼ˆCropï¼‰
    2. éšæœºæ©ç ï¼ˆMaskï¼‰
    3. éšæœºé‡æ’ï¼ˆReorderï¼‰
    4. éšæœºæ›¿æ¢ï¼ˆSubstituteï¼‰
    """
    
    def __init__(
        self,
        crop_ratio=0.6,
        mask_ratio=0.2,
        reorder_ratio=0.2,
        substitute_ratio=0.1,
        num_items=None
    ):
        self.crop_ratio = crop_ratio
        self.mask_ratio = mask_ratio
        self.reorder_ratio = reorder_ratio
        self.substitute_ratio = substitute_ratio
        self.num_items = num_items
    
    def crop(self, seq, mask):
        """éšæœºè£å‰ªåºåˆ—"""
        valid_len = mask.sum().int().item()
        if valid_len <= 2:
            return seq.clone(), mask.clone()
        
        crop_len = max(2, int(valid_len * self.crop_ratio))
        start = torch.randint(0, valid_len - crop_len + 1, (1,)).item()
        
        # æ‰¾åˆ°æœ‰æ•ˆåºåˆ—çš„èµ·å§‹ä½ç½®
        valid_start = (mask == 0).sum().int().item()
        
        new_seq = seq.clone()
        new_mask = mask.clone()
        
        # è£å‰ªï¼šå°†ä¸åœ¨è£å‰ªèŒƒå›´å†…çš„ä½ç½®ç½®ä¸º0
        crop_start = valid_start + start
        crop_end = crop_start + crop_len
        
        new_seq[:crop_start] = 0
        new_seq[crop_end:] = 0
        new_mask[:crop_start] = 0
        new_mask[crop_end:] = 0
        
        return new_seq, new_mask
    
    def mask(self, seq, mask):
        """éšæœºæ©ç éƒ¨åˆ†ç‰©å“"""
        new_seq = seq.clone()
        valid_positions = mask.bool()
        num_valid = valid_positions.sum().item()
        
        if num_valid <= 1:
            return new_seq, mask
        
        num_mask = max(1, int(num_valid * self.mask_ratio))
        valid_indices = torch.where(valid_positions)[0]
        mask_indices = valid_indices[torch.randperm(len(valid_indices))[:num_mask]]
        new_seq[mask_indices] = 0  # ä½¿ç”¨ padding_idx ä½œä¸º mask
        
        return new_seq, mask
    
    def reorder(self, seq, mask):
        """éšæœºé‡æ’éƒ¨åˆ†åºåˆ—"""
        new_seq = seq.clone()
        valid_positions = mask.bool()
        valid_indices = torch.where(valid_positions)[0]
        num_valid = len(valid_indices)
        
        if num_valid <= 2:
            return new_seq, mask
        
        # é€‰æ‹©ä¸€æ®µè¿ç»­åŒºé—´è¿›è¡Œé‡æ’
        reorder_len = max(2, int(num_valid * self.reorder_ratio))
        start = torch.randint(0, num_valid - reorder_len + 1, (1,)).item()
        
        indices_to_reorder = valid_indices[start:start + reorder_len]
        reordered = indices_to_reorder[torch.randperm(reorder_len)]
        
        new_seq[indices_to_reorder] = seq[reordered]
        
        return new_seq, mask
    
    def substitute(self, seq, mask):
        """éšæœºæ›¿æ¢éƒ¨åˆ†ç‰©å“"""
        if self.num_items is None:
            return seq, mask
        
        new_seq = seq.clone()
        valid_positions = mask.bool()
        num_valid = valid_positions.sum().item()
        
        if num_valid <= 1:
            return new_seq, mask
        
        num_sub = max(1, int(num_valid * self.substitute_ratio))
        valid_indices = torch.where(valid_positions)[0]
        sub_indices = valid_indices[torch.randperm(len(valid_indices))[:num_sub]]
        
        # éšæœºæ›¿æ¢ä¸ºå…¶ä»–ç‰©å“
        new_items = torch.randint(1, self.num_items + 1, (num_sub,), device=seq.device)
        new_seq[sub_indices] = new_items
        
        return new_seq, mask
    
    def augment(self, seq, mask, strategy='random'):
        """
        åº”ç”¨æ•°æ®å¢å¼º
        
        Args:
            seq: [L] ç‰©å“åºåˆ—
            mask: [L] æœ‰æ•ˆä½ç½®æ©ç 
            strategy: å¢å¼ºç­–ç•¥ï¼Œ'crop', 'mask', 'reorder', 'substitute', æˆ– 'random'
        """
        if strategy == 'crop':
            return self.crop(seq, mask)
        elif strategy == 'mask':
            return self.mask(seq, mask)
        elif strategy == 'reorder':
            return self.reorder(seq, mask)
        elif strategy == 'substitute':
            return self.substitute(seq, mask)
        elif strategy == 'random':
            # éšæœºé€‰æ‹©ä¸€ç§ç­–ç•¥
            strategies = ['crop', 'mask', 'reorder']
            if self.num_items is not None:
                strategies.append('substitute')
            choice = np.random.choice(strategies)
            return self.augment(seq, mask, choice)
        else:
            return seq, mask


class ContrastiveEncoder(nn.Module):
    """
    å¯¹æ¯”å­¦ä¹ åºåˆ—ç¼–ç å™¨
    
    å°†ç”¨æˆ·å†å²åºåˆ—ç¼–ç ä¸ºå‘é‡è¡¨ç¤ºï¼Œç”¨äºå¯¹æ¯”å­¦ä¹ ã€‚
    """
    
    def __init__(
        self,
        num_items,
        embedding_dim=64,
        hidden_dim=128,
        output_dim=64
    ):
        super(ContrastiveEncoder, self).__init__()
        
        self.item_embedding = nn.Embedding(num_items + 1, embedding_dim, padding_idx=0)
        
        # ä½¿ç”¨ Transformer ç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embedding_dim,
            nhead=4,
            dim_feedforward=hidden_dim,
            dropout=0.1,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)
        
        # æŠ•å½±å¤´ï¼ˆå¯¹æ¯”å­¦ä¹ å…³é”®ç»„ä»¶ï¼‰
        self.projector = nn.Sequential(
            nn.Linear(embedding_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, output_dim)
        )
        
        self._init_weights()
    
    def _init_weights(self):
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
            elif isinstance(module, nn.Embedding):
                nn.init.normal_(module.weight, mean=0, std=0.01)
    
    def forward(self, item_seq, mask):
        """
        Args:
            item_seq: [B, L] ç‰©å“åºåˆ—
            mask: [B, L] æœ‰æ•ˆä½ç½®æ©ç ï¼ˆ1=æœ‰æ•ˆï¼Œ0=paddingï¼‰
        
        Returns:
            z: [B, output_dim] å¯¹æ¯”å­¦ä¹ è¡¨ç¤º
        """
        # åµŒå…¥
        seq_emb = self.item_embedding(item_seq)  # [B, L, D]
        
        # Transformer ç¼–ç ï¼ˆæ³¨æ„ mask å–åï¼‰
        src_key_padding_mask = ~mask.bool()  # True è¡¨ç¤ºå¿½ç•¥
        encoded = self.transformer(seq_emb, src_key_padding_mask=src_key_padding_mask)
        
        # æ± åŒ–ï¼šå–æœ‰æ•ˆä½ç½®çš„å¹³å‡
        mask_expanded = mask.unsqueeze(-1)  # [B, L, 1]
        pooled = (encoded * mask_expanded).sum(dim=1) / mask_expanded.sum(dim=1).clamp(min=1)
        
        # æŠ•å½±
        z = self.projector(pooled)
        
        return z


class InfoNCELoss(nn.Module):
    """
    InfoNCE å¯¹æ¯”æŸå¤±
    
    L = -log(exp(sim(z_i, z_j)/Ï„) / Î£_k exp(sim(z_i, z_k)/Ï„))
    
    å…¶ä¸­ (z_i, z_j) æ˜¯æ­£æ ·æœ¬å¯¹ï¼Œz_k æ˜¯æ‰¹å†…è´Ÿæ ·æœ¬
    """
    
    def __init__(self, temperature=0.1):
        super(InfoNCELoss, self).__init__()
        self.temperature = temperature
    
    def forward(self, z1, z2):
        """
        Args:
            z1: [B, D] å¢å¼ºè§†å›¾1çš„è¡¨ç¤º
            z2: [B, D] å¢å¼ºè§†å›¾2çš„è¡¨ç¤º
        
        Returns:
            loss: å¯¹æ¯”æŸå¤±
        """
        batch_size = z1.shape[0]
        
        # L2 å½’ä¸€åŒ–
        z1 = F.normalize(z1, dim=1)
        z2 = F.normalize(z2, dim=1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        # sim[i, j] = z1[i] Â· z2[j]
        sim_matrix = torch.mm(z1, z2.t()) / self.temperature  # [B, B]
        
        # æ­£æ ·æœ¬åœ¨å¯¹è§’çº¿ä¸Š
        labels = torch.arange(batch_size, device=z1.device)
        
        # äº¤å‰ç†µæŸå¤±ï¼ˆæ­£æ ·æœ¬æ˜¯å¯¹è§’çº¿å…ƒç´ ï¼‰
        loss = F.cross_entropy(sim_matrix, labels) + F.cross_entropy(sim_matrix.t(), labels)
        
        return loss / 2


class DINWithContrastive(nn.Module):
    """
    å¸¦å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒçš„ DIN æ¨¡å‹
    
    è®­ç»ƒæµç¨‹ï¼š
    1. é¢„è®­ç»ƒé˜¶æ®µï¼šä½¿ç”¨å¯¹æ¯”æŸå¤±è®­ç»ƒåºåˆ—ç¼–ç å™¨
    2. å¾®è°ƒé˜¶æ®µï¼šå†»ç»“/å¾®è°ƒç¼–ç å™¨ï¼Œè®­ç»ƒå®Œæ•´ DIN æ¨¡å‹
    """
    
    def __init__(
        self,
        num_items,
        num_users,
        feature_dims,
        embedding_dim=64,
        feature_embedding_dim=16,
        mlp_hidden_dims=[256, 128, 64],
        dropout_rate=0.2,
        contrastive_dim=64,
        temperature=0.1
    ):
        super(DINWithContrastive, self).__init__()
        
        self.num_items = num_items
        self.embedding_dim = embedding_dim
        self.feature_embedding_dim = feature_embedding_dim
        
        # å¯¹æ¯”å­¦ä¹ ç¼–ç å™¨ï¼ˆç”¨äºé¢„è®­ç»ƒï¼‰
        self.contrastive_encoder = ContrastiveEncoder(
            num_items=num_items,
            embedding_dim=embedding_dim,
            hidden_dim=128,
            output_dim=contrastive_dim
        )
        
        # å¯¹æ¯”æŸå¤±
        self.contrastive_loss = InfoNCELoss(temperature)
        
        # DIN ç»„ä»¶ï¼ˆå¤ç”¨ç¼–ç å™¨çš„åµŒå…¥å±‚ï¼‰
        self.item_embedding = self.contrastive_encoder.item_embedding  # å…±äº«åµŒå…¥
        self.user_embedding = nn.Embedding(num_users + 1, feature_embedding_dim)
        self.genre_embedding = nn.Embedding(
            feature_dims.get('primary_genre', 20) + 1, 
            feature_embedding_dim, 
            padding_idx=0
        )
        self.year_embedding = nn.Embedding(
            feature_dims.get('year_bucket', 8) + 1, 
            feature_embedding_dim, 
            padding_idx=0
        )
        self.age_embedding = nn.Embedding(
            feature_dims.get('age_bucket', 10) + 1, 
            feature_embedding_dim
        )
        self.gender_embedding = nn.Embedding(3, feature_embedding_dim)
        self.occupation_embedding = nn.Embedding(
            feature_dims.get('occupation', 25) + 1, 
            feature_embedding_dim
        )
        
        # æ³¨æ„åŠ›å±‚
        self.seq_feature_dim = embedding_dim + 2 * feature_embedding_dim
        self.attention = self._build_attention(self.seq_feature_dim, [64, 32])
        
        # MLP
        mlp_input_dim = (
            self.seq_feature_dim +  # ç”¨æˆ·å…´è¶£
            self.seq_feature_dim +  # ç›®æ ‡ç‰©å“
            feature_embedding_dim +  # ç”¨æˆ·åµŒå…¥
            feature_embedding_dim * 3  # å¹´é¾„ + æ€§åˆ« + èŒä¸š
        )
        
        mlp_layers = []
        prev_dim = mlp_input_dim
        for hidden_dim in mlp_hidden_dims:
            mlp_layers.append(nn.Linear(prev_dim, hidden_dim))
            mlp_layers.append(nn.BatchNorm1d(hidden_dim))
            mlp_layers.append(nn.PReLU())
            mlp_layers.append(nn.Dropout(dropout_rate))
            prev_dim = hidden_dim
        mlp_layers.append(nn.Linear(prev_dim, 1))
        
        self.mlp = nn.Sequential(*mlp_layers)
        
        # æ•°æ®å¢å¼ºå™¨
        self.augmenter = SequenceAugmentation(num_items=num_items)
        
        self._init_weights()
    
    def _build_attention(self, input_dim, hidden_dims):
        """æ„å»ºæ³¨æ„åŠ› MLP"""
        mlp_input = 4 * input_dim
        layers = []
        prev_dim = mlp_input
        for hidden_dim in hidden_dims:
            layers.append(nn.Linear(prev_dim, hidden_dim))
            layers.append(nn.PReLU())
            prev_dim = hidden_dim
        layers.append(nn.Linear(prev_dim, 1))
        return nn.Sequential(*layers)
    
    def _init_weights(self):
        for name, module in self.named_modules():
            # è·³è¿‡ contrastive_encoderï¼ˆå·²ç»åˆå§‹åŒ–è¿‡ï¼‰
            if 'contrastive_encoder' in name:
                continue
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
            elif isinstance(module, nn.Embedding):
                nn.init.normal_(module.weight, mean=0, std=0.01)
    
    def attention_forward(self, query, keys, keys_mask):
        """æ³¨æ„åŠ›è®¡ç®—"""
        batch_size, seq_len, dim = keys.shape
        
        query_expanded = query.unsqueeze(1).expand(-1, seq_len, -1)
        attention_input = torch.cat([
            keys, query_expanded,
            keys * query_expanded,
            keys - query_expanded
        ], dim=-1)
        
        attention_scores = self.attention(attention_input).squeeze(-1)
        
        if keys_mask is not None:
            attention_scores = attention_scores.masked_fill(~keys_mask.bool(), -1e9)
        
        attention_weights = F.softmax(attention_scores, dim=-1)
        weighted_sum = torch.sum(attention_weights.unsqueeze(-1) * keys, dim=1)
        
        return weighted_sum, attention_weights
    
    def contrastive_forward(self, item_seq, mask):
        """
        å¯¹æ¯”å­¦ä¹ å‰å‘ä¼ æ’­
        
        Returns:
            z1, z2: ä¸¤ä¸ªå¢å¼ºè§†å›¾çš„è¡¨ç¤º
        """
        batch_size = item_seq.shape[0]
        
        # ç”Ÿæˆä¸¤ä¸ªå¢å¼ºè§†å›¾
        aug_seq1, aug_mask1 = [], []
        aug_seq2, aug_mask2 = [], []
        
        for i in range(batch_size):
            s1, m1 = self.augmenter.augment(item_seq[i], mask[i], 'random')
            s2, m2 = self.augmenter.augment(item_seq[i], mask[i], 'random')
            aug_seq1.append(s1)
            aug_mask1.append(m1)
            aug_seq2.append(s2)
            aug_mask2.append(m2)
        
        aug_seq1 = torch.stack(aug_seq1)
        aug_mask1 = torch.stack(aug_mask1)
        aug_seq2 = torch.stack(aug_seq2)
        aug_mask2 = torch.stack(aug_mask2)
        
        # ç¼–ç 
        z1 = self.contrastive_encoder(aug_seq1, aug_mask1)
        z2 = self.contrastive_encoder(aug_seq2, aug_mask2)
        
        return z1, z2
    
    def forward(self, batch, return_contrastive_loss=False):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            batch: æ•°æ®æ‰¹æ¬¡
            return_contrastive_loss: æ˜¯å¦è¿”å›å¯¹æ¯”æŸå¤±ï¼ˆç”¨äºè”åˆè®­ç»ƒï¼‰
        """
        # å†å²åºåˆ—åµŒå…¥
        seq_item_emb = self.item_embedding(batch['item_seq'])
        seq_genre_emb = self.genre_embedding(batch['history_genres'])
        seq_year_emb = self.year_embedding(batch['history_years'])
        seq_combined = torch.cat([seq_item_emb, seq_genre_emb, seq_year_emb], dim=-1)
        
        # ç›®æ ‡ç‰©å“åµŒå…¥
        target_item_emb = self.item_embedding(batch['target_item'])
        target_genre_emb = self.genre_embedding(batch['item_genre'])
        target_year_emb = self.year_embedding(batch['item_year'])
        target_combined = torch.cat([target_item_emb, target_genre_emb, target_year_emb], dim=-1)
        
        # æ³¨æ„åŠ›
        user_interest, _ = self.attention_forward(
            target_combined, seq_combined, batch['item_seq_mask']
        )
        
        # ç”¨æˆ·ç‰¹å¾
        user_emb = self.user_embedding(batch['user_id'])
        age_emb = self.age_embedding(batch['user_age'])
        gender_emb = self.gender_embedding(batch['user_gender'])
        occupation_emb = self.occupation_embedding(batch['user_occupation'])
        
        # æ‹¼æ¥å¹¶é¢„æµ‹
        features = torch.cat([
            user_interest, target_combined,
            user_emb, age_emb, gender_emb, occupation_emb
        ], dim=-1)
        
        logits = self.mlp(features).squeeze(-1)
        
        if return_contrastive_loss:
            z1, z2 = self.contrastive_forward(batch['item_seq'], batch['item_seq_mask'])
            cl_loss = self.contrastive_loss(z1, z2)
            return logits, cl_loss
        
        return logits


class ContrastiveTrainer(RichTrainer):
    """
    å¯¹æ¯”å­¦ä¹ è®­ç»ƒå™¨
    
    æ”¯æŒä¸¤ç§è®­ç»ƒæ¨¡å¼ï¼š
    1. é¢„è®­ç»ƒæ¨¡å¼ï¼šåªè®­ç»ƒå¯¹æ¯”æŸå¤±
    2. è”åˆè®­ç»ƒæ¨¡å¼ï¼šå¯¹æ¯”æŸå¤± + CTR æŸå¤±
    """
    
    def __init__(
        self,
        model,
        device='cpu',
        learning_rate=1e-3,
        weight_decay=1e-5,
        contrastive_weight=0.1,  # å¯¹æ¯”æŸå¤±æƒé‡
        use_tensorboard=True,
        log_dir='./runs',
        experiment_name=None
    ):
        super().__init__(
            model=model,
            device=device,
            learning_rate=learning_rate,
            weight_decay=weight_decay,
            use_tensorboard=use_tensorboard,
            log_dir=log_dir,
            experiment_name=experiment_name
        )
        self.contrastive_weight = contrastive_weight
    
    def pretrain_epoch(self, train_loader, show_progress=True):
        """é¢„è®­ç»ƒä¸€ä¸ª epochï¼ˆåªç”¨å¯¹æ¯”æŸå¤±ï¼‰"""
        self.model.train()
        total_loss = 0
        
        from tqdm import tqdm
        iterator = tqdm(train_loader, desc='Pretraining') if show_progress else train_loader
        
        for batch in iterator:
            batch = self._move_batch_to_device(batch)
            
            self.optimizer.zero_grad()
            
            # åªè®¡ç®—å¯¹æ¯”æŸå¤±
            z1, z2 = self.model.contrastive_forward(
                batch['item_seq'], batch['item_seq_mask']
            )
            loss = self.model.contrastive_loss(z1, z2)
            
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)
            self.optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / len(train_loader)
    
    def train_epoch_joint(self, train_loader, show_progress=True):
        """è”åˆè®­ç»ƒä¸€ä¸ª epochï¼ˆå¯¹æ¯”æŸå¤± + CTR æŸå¤±ï¼‰"""
        self.model.train()
        total_loss = 0
        total_ctr_loss = 0
        total_cl_loss = 0
        
        from tqdm import tqdm
        iterator = tqdm(train_loader, desc='Joint Training') if show_progress else train_loader
        
        for batch in iterator:
            batch = self._move_batch_to_device(batch)
            
            self.optimizer.zero_grad()
            
            # CTR æŸå¤± + å¯¹æ¯”æŸå¤±
            logits, cl_loss = self.model(batch, return_contrastive_loss=True)
            ctr_loss = self.criterion(logits, batch['label'])
            
            loss = ctr_loss + self.contrastive_weight * cl_loss
            
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)
            self.optimizer.step()
            
            total_loss += loss.item()
            total_ctr_loss += ctr_loss.item()
            total_cl_loss += cl_loss.item()
        
        return {
            'total_loss': total_loss / len(train_loader),
            'ctr_loss': total_ctr_loss / len(train_loader),
            'cl_loss': total_cl_loss / len(train_loader)
        }
    
    def pretrain(self, train_loader, epochs=10, show_progress=True):
        """å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒ"""
        print("=" * 60)
        print("å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒ")
        print("=" * 60)
        
        for epoch in range(epochs):
            loss = self.pretrain_epoch(train_loader, show_progress)
            print(f"Pretrain Epoch {epoch+1}/{epochs} - CL Loss: {loss:.4f}")
            
            if self.use_tensorboard and self.writer is not None:
                self.writer.add_scalar('Pretrain/cl_loss', loss, epoch)
        
        return self
    
    def fit_joint(
        self,
        train_loader,
        valid_loader,
        epochs=20,
        early_stopping_patience=5,
        show_progress=True
    ):
        """è”åˆè®­ç»ƒï¼ˆå¯¹æ¯”æŸå¤± + CTR æŸå¤±ï¼‰"""
        best_valid_auc = 0
        patience_counter = 0
        best_model_state = None
        
        for epoch in range(epochs):
            losses = self.train_epoch_joint(train_loader, show_progress)
            valid_metrics = self.evaluate(valid_loader)
            
            print(f"Epoch {epoch+1}/{epochs} - "
                  f"Total: {losses['total_loss']:.4f} - "
                  f"CTR: {losses['ctr_loss']:.4f} - "
                  f"CL: {losses['cl_loss']:.4f} - "
                  f"Valid AUC: {valid_metrics['auc']:.4f}")
            
            if self.use_tensorboard and self.writer is not None:
                self.writer.add_scalar('Loss/total', losses['total_loss'], epoch)
                self.writer.add_scalar('Loss/ctr', losses['ctr_loss'], epoch)
                self.writer.add_scalar('Loss/contrastive', losses['cl_loss'], epoch)
                self.writer.add_scalar('Metrics/valid_auc', valid_metrics['auc'], epoch)
            
            if valid_metrics['auc'] > best_valid_auc:
                best_valid_auc = valid_metrics['auc']
                best_model_state = copy.deepcopy(self.model.state_dict())
                patience_counter = 0
            else:
                patience_counter += 1
                if patience_counter >= early_stopping_patience:
                    print(f"Early stopping at epoch {epoch+1}")
                    break
        
        if best_model_state is not None:
            self.model.load_state_dict(best_model_state)
        
        if self.use_tensorboard and self.writer is not None:
            self.writer.close()
        
        return {
            'best_valid_auc': best_valid_auc,
            'final_epoch': epoch + 1
        }


# ========================================
# å®éªŒä¸»å‡½æ•°
# ========================================

def run_adaptive_decay_experiment(dataset_name='ml-100k', epochs=50, batch_size=256, device=None):
    """
    è¿è¡Œè‡ªé€‚åº”è¡°å‡å®éªŒ
    
    Args:
        dataset_name: æ•°æ®é›†åç§°
        epochs: è®­ç»ƒè½®æ•°
        batch_size: æ‰¹æ¬¡å¤§å°
        device: è®¾å¤‡ (None åˆ™è‡ªåŠ¨æ£€æµ‹)
    
    Returns:
        list: å®éªŒç»“æœåˆ—è¡¨
    """
    print("\n" + "=" * 80)
    print("ğŸ”¬ å®éªŒ 4.1: è‡ªé€‚åº”æ—¶é—´è¡°å‡")
    print("=" * 80)
    
    DEVICE = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"è®¾å¤‡: {DEVICE}")
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“¦ åŠ è½½æ•°æ®...")
    train_loader, valid_loader, test_loader, dataset_info, fp = get_rich_dataloaders(
        data_dir='./data',
        dataset_name=dataset_name,
        max_seq_length=50,
        batch_size=batch_size
    )
    
    # åŠ è½½ Top-K è¯„ä¼°æ•°æ®
    print("ğŸ“Š åŠ è½½ Top-K è¯„ä¼°æ•°æ®...")
    try:
        eval_data, _, fp_eval, ie_eval = get_topk_eval_data('./data', dataset_name, 50)
        print(f"   {len(eval_data)} ä¸ªæµ‹è¯•ç”¨æˆ·")
        enable_topk = True
    except Exception as e:
        print(f"   âš ï¸ Top-K æ•°æ®åŠ è½½å¤±è´¥: {e}")
        eval_data, fp_eval, ie_eval = None, None, None
        enable_topk = False
    
    # å®éªŒé…ç½®
    configs = [
        {'name': 'Fixed-Decay-0.05', 'learnable': False, 'init_decay': 0.05, 'per_user': False},
        {'name': 'Fixed-Decay-0.1', 'learnable': False, 'init_decay': 0.1, 'per_user': False},
        {'name': 'Fixed-Decay-0.2', 'learnable': False, 'init_decay': 0.2, 'per_user': False},
        {'name': 'Learnable-Decay', 'learnable': True, 'init_decay': 0.1, 'per_user': False},
        {'name': 'Per-User-Decay', 'learnable': True, 'init_decay': 0.1, 'per_user': True},
    ]
    
    results = []
    
    for config in configs:
        print(f"\nğŸš€ æµ‹è¯•: {config['name']}")
        print("-" * 40)
        
        try:
            model = DINAdaptiveDecay(
                num_items=dataset_info['num_items'],
                num_users=dataset_info['num_users'],
                feature_dims=dataset_info['feature_dims'],
                embedding_dim=64,
                init_decay=config['init_decay'],
                learnable_decay=config['learnable'],
                per_user_decay=config['per_user']
            )
            
            trainer = RichTrainer(
                model=model, 
                device=DEVICE,
                use_tensorboard=True,
                experiment_name=f'exp4_adaptive_{config["name"]}'
            )
            
            t1 = time.time()
            train_result = trainer.fit(
                train_loader=train_loader,
                valid_loader=valid_loader,
                epochs=20,
                early_stopping_patience=5,
                show_progress=True
            )
            train_time = time.time() - t1
            
            test_metrics = trainer.evaluate(test_loader)
            
            # è·å–å­¦ä¹ åˆ°çš„è¡°å‡ç‡
            learned_decay = model.get_decay_rate()
            
            result = {
                'variant': config['name'],
                'test_auc': test_metrics['auc'],
                'test_logloss': test_metrics['logloss'],
                'best_valid_auc': train_result['best_valid_auc'],
                'train_time_sec': train_time,
                'init_decay': config['init_decay'],
                'learned_decay': learned_decay,
                'status': 'success'
            }
            
            # Top-K è¯„ä¼°
            if enable_topk and eval_data is not None:
                topk_metrics = evaluate_topk_metrics(
                    model, eval_data, fp_eval, ie_eval, 50, DEVICE
                )
                result.update(topk_metrics)
                print(f"âœ… AUC={test_metrics['auc']:.4f}, HR@10={topk_metrics['HR@10']:.4f}, NDCG@10={topk_metrics['NDCG@10']:.4f}")
            else:
                print(f"âœ… Test AUC: {test_metrics['auc']:.4f}")
            
            if learned_decay is not None:
                print(f"   å­¦ä¹ åˆ°çš„è¡°å‡ç‡: {learned_decay:.4f}")
            
            results.append(result)
                
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            
            results.append({
                'variant': config['name'],
                'test_auc': None,
                'test_logloss': None,
                'best_valid_auc': None,
                'train_time_sec': None,
                'init_decay': config['init_decay'],
                'learned_decay': None,
                'status': f'error: {str(e)[:100]}'
            })
    
    # ä¿å­˜ç»“æœ
    RESULTS_DIR = os.path.join(os.path.dirname(__file__), 'results_gpu')
    os.makedirs(RESULTS_DIR, exist_ok=True)
    
    df_results = pd.DataFrame(results)
    df_results.to_csv(os.path.join(RESULTS_DIR, f'experiment4_adaptive_decay_{dataset_name}.csv'), index=False)
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ è‡ªé€‚åº”è¡°å‡å®éªŒç»“æœ")
    print("=" * 60)
    print(df_results[['variant', 'test_auc', 'learned_decay']].to_string(index=False))
    
    # è¿”å› list æ ¼å¼ï¼ˆå…¼å®¹ run_all_gpu.pyï¼‰
    return results


def run_contrastive_experiment(dataset_name='ml-100k', epochs=50, batch_size=256, device=None):
    """
    è¿è¡Œå¯¹æ¯”å­¦ä¹ å®éªŒ
    
    Args:
        dataset_name: æ•°æ®é›†åç§°
        epochs: è®­ç»ƒè½®æ•°
        batch_size: æ‰¹æ¬¡å¤§å°
        device: è®¾å¤‡ (None åˆ™è‡ªåŠ¨æ£€æµ‹)
    
    Returns:
        list: å®éªŒç»“æœåˆ—è¡¨
    """
    print("\n" + "=" * 80)
    print("ğŸ”¬ å®éªŒ 4.2: å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒ")
    print("=" * 80)
    
    DEVICE = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"è®¾å¤‡: {DEVICE}")
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“¦ åŠ è½½æ•°æ®...")
    train_loader, valid_loader, test_loader, dataset_info, fp = get_rich_dataloaders(
        data_dir='./data',
        dataset_name=dataset_name,
        max_seq_length=50,
        batch_size=batch_size
    )
    
    # åŠ è½½ Top-K è¯„ä¼°æ•°æ®
    print("ğŸ“Š åŠ è½½ Top-K è¯„ä¼°æ•°æ®...")
    try:
        eval_data, _, fp_eval, ie_eval = get_topk_eval_data('./data', dataset_name, 50)
        print(f"   {len(eval_data)} ä¸ªæµ‹è¯•ç”¨æˆ·")
        enable_topk = True
    except Exception as e:
        print(f"   âš ï¸ Top-K æ•°æ®åŠ è½½å¤±è´¥: {e}")
        eval_data, fp_eval, ie_eval = None, None, None
        enable_topk = False
    
    # å®éªŒé…ç½®
    configs = [
        {'name': 'No-Pretrain', 'pretrain_epochs': 0, 'joint': False, 'cl_weight': 0.0},
        {'name': 'Pretrain-5ep', 'pretrain_epochs': 5, 'joint': False, 'cl_weight': 0.0},
        {'name': 'Pretrain-10ep', 'pretrain_epochs': 10, 'joint': False, 'cl_weight': 0.0},
        {'name': 'Joint-0.05', 'pretrain_epochs': 0, 'joint': True, 'cl_weight': 0.05},
        {'name': 'Joint-0.1', 'pretrain_epochs': 0, 'joint': True, 'cl_weight': 0.1},
        {'name': 'Pretrain+Joint', 'pretrain_epochs': 5, 'joint': True, 'cl_weight': 0.05},
    ]
    
    results = []
    
    for config in configs:
        print(f"\nğŸš€ æµ‹è¯•: {config['name']}")
        print("-" * 40)
        
        try:
            model = DINWithContrastive(
                num_items=dataset_info['num_items'],
                num_users=dataset_info['num_users'],
                feature_dims=dataset_info['feature_dims'],
                embedding_dim=64,
                contrastive_dim=64,
                temperature=0.1
            )
            
            trainer = ContrastiveTrainer(
                model=model, 
                device=DEVICE,
                contrastive_weight=config['cl_weight'],
                use_tensorboard=True,
                experiment_name=f'exp4_contrastive_{config["name"]}'
            )
            
            t1 = time.time()
            
            # é¢„è®­ç»ƒé˜¶æ®µ
            if config['pretrain_epochs'] > 0:
                print(f"é¢„è®­ç»ƒ {config['pretrain_epochs']} epochs...")
                trainer.pretrain(train_loader, epochs=config['pretrain_epochs'])
            
            # å¾®è°ƒ/è”åˆè®­ç»ƒé˜¶æ®µ
            if config['joint']:
                train_result = trainer.fit_joint(
                    train_loader=train_loader,
                    valid_loader=valid_loader,
                    epochs=20,
                    early_stopping_patience=5,
                    show_progress=True
                )
            else:
                train_result = trainer.fit(
                    train_loader=train_loader,
                    valid_loader=valid_loader,
                    epochs=20,
                    early_stopping_patience=5,
                    show_progress=True
                )
            
            train_time = time.time() - t1
            
            test_metrics = trainer.evaluate(test_loader)
            
            result = {
                'variant': config['name'],
                'test_auc': test_metrics['auc'],
                'test_logloss': test_metrics['logloss'],
                'best_valid_auc': train_result['best_valid_auc'],
                'train_time_sec': train_time,
                'pretrain_epochs': config['pretrain_epochs'],
                'cl_weight': config['cl_weight'],
                'status': 'success'
            }
            
            # Top-K è¯„ä¼°
            if enable_topk and eval_data is not None:
                topk_metrics = evaluate_topk_metrics(
                    model, eval_data, fp_eval, ie_eval, 50, DEVICE
                )
                result.update(topk_metrics)
                print(f"âœ… AUC={test_metrics['auc']:.4f}, HR@10={topk_metrics['HR@10']:.4f}, NDCG@10={topk_metrics['NDCG@10']:.4f}")
            else:
                print(f"âœ… Test AUC: {test_metrics['auc']:.4f}")
            
            results.append(result)
                
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            
            results.append({
                'variant': config['name'],
                'test_auc': None,
                'test_logloss': None,
                'best_valid_auc': None,
                'train_time_sec': None,
                'pretrain_epochs': config['pretrain_epochs'],
                'cl_weight': config['cl_weight'],
                'status': f'error: {str(e)[:100]}'
            })
    
    # ä¿å­˜ç»“æœ
    RESULTS_DIR = os.path.join(os.path.dirname(__file__), 'results_gpu')
    os.makedirs(RESULTS_DIR, exist_ok=True)
    
    df_results = pd.DataFrame(results)
    df_results.to_csv(os.path.join(RESULTS_DIR, f'experiment4_contrastive_{dataset_name}.csv'), index=False)
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ å¯¹æ¯”å­¦ä¹ å®éªŒç»“æœ")
    print("=" * 60)
    print(df_results[['variant', 'test_auc', 'pretrain_epochs', 'cl_weight']].to_string(index=False))
    
    # è¿”å› list æ ¼å¼ï¼ˆå…¼å®¹ run_all_gpu.pyï¼‰
    return results


def run_full_experiment(dataset_name='ml-100k'):
    """
    è¿è¡Œå®Œæ•´å®éªŒå››
    """
    print("=" * 80)
    print("ğŸ§ª å®éªŒå››ï¼šDIN é«˜çº§æ”¹è¿›å®éªŒ")
    print("=" * 80)
    print("åŒ…å«ï¼š")
    print("  1. è‡ªé€‚åº”æ—¶é—´è¡°å‡ï¼ˆAdaptive Time Decayï¼‰")
    print("  2. å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒï¼ˆContrastive Learningï¼‰")
    print("=" * 80)
    
    start_time = datetime.now()
    
    # Part 1: è‡ªé€‚åº”è¡°å‡
    df_adaptive = run_adaptive_decay_experiment(dataset_name)
    
    # Part 2: å¯¹æ¯”å­¦ä¹ 
    df_contrastive = run_contrastive_experiment(dataset_name)
    
    # ç»¼åˆæŠ¥å‘Š
    end_time = datetime.now()
    total_time = (end_time - start_time).total_seconds()
    
    RESULTS_DIR = os.path.join(os.path.dirname(__file__), 'results')
    
    report = {
        'experiment': 'Experiment 4: Advanced DIN Improvements',
        'dataset': dataset_name,
        'total_time_seconds': total_time,
        'adaptive_decay_results': df_adaptive.to_dict('records'),
        'contrastive_results': df_contrastive.to_dict('records'),
        'conclusions': {
            'adaptive_decay': 'è‡ªé€‚åº”è¡°å‡å¯å­¦ä¹ æœ€ä¼˜è¡°å‡å‚æ•°',
            'contrastive_learning': 'å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒå¯æ”¹å–„åºåˆ—è¡¨ç¤º'
        }
    }
    
    # æ‰¾å‡ºæœ€ä½³ç»“æœ
    df_adaptive_success = df_adaptive[df_adaptive['status'] == 'success']
    df_contrastive_success = df_contrastive[df_contrastive['status'] == 'success']
    
    if len(df_adaptive_success) > 0:
        best_adaptive = df_adaptive_success.loc[df_adaptive_success['test_auc'].idxmax()]
        report['best_adaptive_decay'] = {
            'variant': best_adaptive['variant'],
            'auc': float(best_adaptive['test_auc'])
        }
    
    if len(df_contrastive_success) > 0:
        best_contrastive = df_contrastive_success.loc[df_contrastive_success['test_auc'].idxmax()]
        report['best_contrastive'] = {
            'variant': best_contrastive['variant'],
            'auc': float(best_contrastive['test_auc'])
        }
    
    report_file = os.path.join(RESULTS_DIR, f'experiment4_{dataset_name}_report.json')
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print("\n" + "=" * 80)
    print("ğŸ‰ å®éªŒå››å®Œæˆ!")
    print("=" * 80)
    print(f"æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
    print(f"æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    if 'best_adaptive_decay' in report:
        print(f"\nğŸ† è‡ªé€‚åº”è¡°å‡æœ€ä½³: {report['best_adaptive_decay']['variant']} "
              f"(AUC={report['best_adaptive_decay']['auc']:.4f})")
    
    if 'best_contrastive' in report:
        print(f"ğŸ† å¯¹æ¯”å­¦ä¹ æœ€ä½³: {report['best_contrastive']['variant']} "
              f"(AUC={report['best_contrastive']['auc']:.4f})")
    
    return df_adaptive, df_contrastive, report


# ========================================
# å…¥å£ç‚¹
# ========================================

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='å®éªŒå››ï¼šDIN é«˜çº§æ”¹è¿›')
    parser.add_argument('--dataset', type=str, default='ml-100k', 
                        choices=['ml-100k', 'ml-1m'],
                        help='æ•°æ®é›†åç§°')
    parser.add_argument('--part', type=str, default='all',
                        choices=['all', 'adaptive', 'contrastive'],
                        help='è¿è¡Œå“ªéƒ¨åˆ†å®éªŒ')
    
    args = parser.parse_args()
    
    if args.part == 'adaptive':
        run_adaptive_decay_experiment(args.dataset)
    elif args.part == 'contrastive':
        run_contrastive_experiment(args.dataset)
    else:
        run_full_experiment(args.dataset)
