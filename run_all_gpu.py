#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
äº‘ç«¯ GPU å®Œæ•´å®éªŒè„šæœ¬

é€‚åˆåœ¨ AutoDL / Colab / é˜¿é‡Œäº‘ç­‰ GPU ç¯å¢ƒè¿è¡Œã€‚
æ”¯æŒ ml-100k å’Œ ml-1m åŒæ•°æ®é›†ã€‚
åŒ…å«å…¨éƒ¨å››ä¸ªå®éªŒã€‚

ä½¿ç”¨æ–¹æ³•:
    python run_all_gpu.py                    # è¿è¡Œæ‰€æœ‰å®éªŒï¼ˆä¸¤ä¸ªæ•°æ®é›†ï¼‰
    python run_all_gpu.py --dataset ml-100k  # åªè¿è¡Œ ml-100k
    python run_all_gpu.py --dataset ml-1m    # åªè¿è¡Œ ml-1m
    python run_all_gpu.py --quick            # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    
    # å•ç‹¬è¿è¡ŒæŸä¸ªå®éªŒ
    python run_all_gpu.py --exp 1            # åªè¿è¡Œå®éªŒ1ï¼ˆæ¨¡å‹å¯¹æ¯”ï¼‰
    python run_all_gpu.py --exp 2            # åªè¿è¡Œå®éªŒ2ï¼ˆæ–¹æ³•å¯¹æ¯”ï¼‰
    python run_all_gpu.py --exp 3            # åªè¿è¡Œå®éªŒ3ï¼ˆæ¶ˆèå®éªŒï¼‰
    python run_all_gpu.py --exp 4            # åªè¿è¡Œå®éªŒ4ï¼ˆé«˜çº§æ”¹è¿›ï¼‰
    python run_all_gpu.py --exp 1,2,3        # è¿è¡Œå®éªŒ1-3
    python run_all_gpu.py --exp 1,3,4        # è¿è¡Œå®éªŒ1ã€3ã€4

é¢„ä¼°æ—¶é—´ (å• GPU, ä¸¤ä¸ªæ•°æ®é›†):
    å®éªŒ1ï¼ˆåºåˆ—é•¿åº¦+æ¨¡å‹å¯¹æ¯”ï¼‰: çº¦ 40-60 åˆ†é’Ÿ
    å®éªŒ2ï¼ˆæ–¹æ³•å¯¹æ¯”+æ··åˆç²¾æ’ï¼‰: çº¦ 30-40 åˆ†é’Ÿ
    å®éªŒ3ï¼ˆæ¶ˆèå®éªŒï¼‰:          çº¦ 20-30 åˆ†é’Ÿ
    å®éªŒ4ï¼ˆé«˜çº§æ”¹è¿›ï¼‰:          çº¦ 60-90 åˆ†é’Ÿ
    æ€»è®¡:                       çº¦ 2.5-4 å°æ—¶
"""

import os
import sys
import argparse
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import json
import time
from tqdm import tqdm

from data_loader import get_rich_dataloaders, get_topk_eval_data, build_topk_batch_multi
from models import DINRichLite, SimpleAveragePoolingRich, GRU4Rec, SASRec, NARM, AttentionLayer
from trainer import RichTrainer, measure_inference_speed_rich
from feature_engineering import FeatureProcessor, InteractionFeatureExtractor, prepare_lightgbm_features

try:
    import lightgbm as lgb
    HAS_LIGHTGBM = True
except ImportError:
    HAS_LIGHTGBM = False
    print("âš ï¸ LightGBM æœªå®‰è£…ï¼Œæ··åˆç²¾æ’å°†è·³è¿‡")

# ========================================
# é…ç½®
# ========================================

parser = argparse.ArgumentParser(description='äº‘ç«¯ GPU å®Œæ•´å®éªŒ')
parser.add_argument('--dataset', type=str, default='both', 
                    choices=['ml-100k', 'ml-1m', 'both'],
                    help='æ•°æ®é›†é€‰æ‹©')
parser.add_argument('--quick', action='store_true', 
                    help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼ˆå‡å°‘ epochs å’Œåºåˆ—é•¿åº¦ï¼‰')
parser.add_argument('--epochs', type=int, default=50,
                    help='è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤ 50ï¼‰')
parser.add_argument('--exp', type=str, default='all',
                    help='è¿è¡Œå“ªäº›å®éªŒ: 1, 2, 3, 4, 1,2,3, all')
parser.add_argument('--no-topk', action='store_true',
                    help='ç¦ç”¨ Top-K è¯„ä¼°ï¼ˆåŠ é€Ÿè®­ç»ƒï¼‰')
parser.add_argument('--topk-sample', type=str, default='auto',
                    help='Top-K è¯„ä¼°é‡‡æ ·ç”¨æˆ·æ•°ï¼ˆé»˜è®¤ autoï¼šml-100kå…¨é‡ï¼Œml-1mé‡‡æ ·2000ï¼›å¯æŒ‡å®šæ•°å­—æˆ–Noneï¼‰')
parser.add_argument('--exp4-part', type=str, default='all',
                    choices=['all', 'adaptive', 'contrastive'],
                    help='å®éªŒ4å­ä»»åŠ¡: all, adaptive, contrastive')
args = parser.parse_args()

# è§£æè¦è¿è¡Œçš„å®éªŒ
if args.exp == 'all':
    EXPERIMENTS_TO_RUN = [1, 2, 3, 4]
else:
    EXPERIMENTS_TO_RUN = [int(x.strip()) for x in args.exp.split(',')]

# Top-K è¯„ä¼°å¼€å…³
ENABLE_TOPK = not args.no_topk

# Top-K é‡‡æ ·ç­–ç•¥
# - 'auto': ml-100kå…¨é‡ï¼Œml-1mé‡‡æ ·2000ï¼ˆé»˜è®¤ï¼Œæ¨èï¼‰
# - æ•°å­—: æŒ‡å®šé‡‡æ ·æ•°
# - None: å…¨é‡è¯„ä¼°ï¼ˆæ…¢ï¼‰
TOPK_SAMPLE_CONFIG = args.topk_sample

def get_topk_sample_users(dataset_name, config):
    """
    æ™ºèƒ½å†³å®š Top-K è¯„ä¼°çš„é‡‡æ ·ç”¨æˆ·æ•°
    
    Args:
        dataset_name: æ•°æ®é›†åç§°
        config: 'auto' / æ•°å­— / None
    
    Returns:
        int or None: é‡‡æ ·ç”¨æˆ·æ•°ï¼ŒNone è¡¨ç¤ºå…¨é‡
    
    ç»Ÿè®¡å­¦ä¾æ®ï¼š
    - 1000 æ ·æœ¬: 95%ç½®ä¿¡åº¦ï¼Œè¯¯å·®Â±3.1%
    - 2000 æ ·æœ¬: 95%ç½®ä¿¡åº¦ï¼Œè¯¯å·®Â±1.8%
    - ml-100k ä»…943ç”¨æˆ·ï¼Œå…¨é‡è¯„ä¼°
    """
    if config == 'auto':
        # æ™ºèƒ½æ¨¡å¼ï¼šå°æ•°æ®é›†å…¨é‡ï¼Œå¤§æ•°æ®é›†é‡‡æ ·
        if dataset_name == 'ml-100k':
            return None  # å…¨é‡ï¼ˆ943ç”¨æˆ·ï¼‰
        elif dataset_name == 'ml-1m':
            return 2000  # é‡‡æ ·ï¼ˆè¯¯å·®Â±1.8%ï¼‰
        else:
            return 2000  # å…¶ä»–æ•°æ®é›†é»˜è®¤é‡‡æ ·
    elif config is None or config == 'None':
        return None  # å…¨é‡
    else:
        try:
            return int(config)  # æŒ‡å®šé‡‡æ ·æ•°
        except:
            return None

# è®¾å¤‡æ£€æµ‹
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
NUM_GPUS = torch.cuda.device_count() if DEVICE == 'cuda' else 0
USE_MULTI_GPU = NUM_GPUS > 1

# å®éªŒå‚æ•°
if args.quick:
    EPOCHS = 10
    SEQ_LENGTHS = [20, 50]
    BATCH_SIZE = 1024
else:
    EPOCHS = args.epochs
    SEQ_LENGTHS = [20, 50, 100, 150]
    # 3x RTX 4090 (24GB each) - å¤§å¹…å¢åŠ batchå……åˆ†åˆ©ç”¨æ˜¾å­˜
    # æ¨¡å‹è¾ƒå°ï¼Œå¯ä»¥ç”¨æ›´å¤§çš„batchæé«˜GPUåˆ©ç”¨ç‡
    BASE_BATCH_SIZE = 4096 if DEVICE == 'cuda' else 256
    # å¤šGPUæ—¶å……åˆ†åˆ©ç”¨æ‰€æœ‰æ˜¾å¡
    if USE_MULTI_GPU:
        # 3x4090: æ¯å¡4096ï¼Œæ€»batch = 12288
        BATCH_SIZE = BASE_BATCH_SIZE * NUM_GPUS
    else:
        BATCH_SIZE = BASE_BATCH_SIZE

EMBEDDING_DIM = 64

# SASRec é•¿åºåˆ—æ—¶éœ€è¦å‡å° batch sizeï¼ˆå› ä¸º O(LÂ²) å†…å­˜å¤æ‚åº¦ï¼‰
# è®¡ç®—å…¬å¼ï¼šæ˜¾å­˜ âˆ batch Ã— seqÂ² Ã— heads
def get_adaptive_batch_size(model_name, seq_length, base_batch_size):
    """
    æ ¹æ®æ¨¡å‹å’Œåºåˆ—é•¿åº¦è‡ªé€‚åº”è°ƒæ•´ batch size
    SASRec çš„æ³¨æ„åŠ›çŸ©é˜µæ˜¯ [B, H, L, L]ï¼Œæ˜¾å­˜å ç”¨ä¸ LÂ² æˆæ­£æ¯”
    3x RTX 4090 (72GBæ€»æ˜¾å­˜) å¯ä»¥å¤„ç†æ›´å¤§çš„batch
    """
    if model_name == 'SASRec' and seq_length > 100:
        # seq=150 æ—¶ï¼Œæ³¨æ„åŠ›çŸ©é˜µæ˜¯ seq=100 çš„ 2.25 å€
        # 3x4090æœ‰å……è¶³æ˜¾å­˜ï¼Œåªéœ€è½»å¾®ç¼©å‡
        scale = (100 / seq_length) ** 1.5  # æ¯”ä¹‹å‰æ›´æ¿€è¿›
        return max(1024, int(base_batch_size * scale))
    return base_batch_size

# Top-K è¯„ä¼°å‚æ•°
TOPK_VALUES = [5, 10, 20]  # è¯„ä¼°çš„ K å€¼
NUM_NEG_SAMPLES = 99  # è´Ÿé‡‡æ ·æ•°é‡ï¼ˆåŠ ä¸Šæ­£æ ·æœ¬å…± 100 ä¸ªå€™é€‰ï¼‰

# æ ¹æ® CPU æ ¸æ•°è®¾ç½® num_workers
# å¤š GPU æ—¶å¯ä»¥å¢åŠ  workers
import multiprocessing
CPU_COUNT = multiprocessing.cpu_count()
# 48 vCPU å¯ä»¥ä½¿ç”¨æ›´å¤š workers åŠ é€Ÿæ•°æ®åŠ è½½
# æ¯ä¸ª GPU åˆ†é… 4-6 ä¸ª workers
NUM_WORKERS = min(18, CPU_COUNT - 2) if DEVICE == 'cuda' else 0

# é¢„å–å› å­ï¼šæ¯ä¸ª worker é¢„åŠ è½½çš„ batch æ•°
# 3x4090 é«˜ååé‡ï¼Œå¢åŠ é¢„å–å‡å°‘ç­‰å¾…
PREFETCH_FACTOR = 6  # é»˜è®¤æ˜¯ 2ï¼Œå¢åŠ å¯ä»¥å‡å°‘ GPU ç­‰å¾…

MODELS_TO_TEST = ['DIN', 'GRU4Rec', 'SASRec', 'NARM', 'AvgPool']

# TensorBoard é…ç½®
ENABLE_TENSORBOARD = True
# AutoDL é»˜è®¤çš„ TensorBoard æ—¥å¿—ç›®å½•æ˜¯ /root/tf-logs
# æœ¬åœ°æµ‹è¯•æ—¶ä½¿ç”¨ ./runs
import platform
if platform.system() == 'Linux' and os.path.exists('/root'):
    TENSORBOARD_LOG_DIR = '/root/tf-logs'  # AutoDL é»˜è®¤ç›®å½•
else:
    TENSORBOARD_LOG_DIR = './runs'  # æœ¬åœ° Windows/Mac

# æ•°æ®é›†
if args.dataset == 'both':
    DATASETS = ['ml-100k', 'ml-1m']
else:
    DATASETS = [args.dataset]

# ç»“æœç›®å½•
RESULTS_DIR = os.path.join(os.path.dirname(__file__), 'results_gpu')
os.makedirs(RESULTS_DIR, exist_ok=True)

print("=" * 80)
print("ğŸš€ äº‘ç«¯ GPU å®Œæ•´å®éªŒ")
print("=" * 80)
print(f"è®¾å¤‡: {DEVICE}")
if DEVICE == 'cuda':
    for i in range(NUM_GPUS):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    if USE_MULTI_GPU:
        print(f"ğŸ”¥ å¤š GPU æ¨¡å¼: {NUM_GPUS} å¼ å¡ï¼ŒDataParallel åŠ é€Ÿ")
print(f"æ•°æ®é›†: {DATASETS}")
print(f"å®éªŒ: {EXPERIMENTS_TO_RUN}")
print(f"Epochs: {EPOCHS}")
print(f"åºåˆ—é•¿åº¦: {SEQ_LENGTHS}")
print(f"Batch Size: {BATCH_SIZE}" + (f" ({BATCH_SIZE // NUM_GPUS} Ã— {NUM_GPUS} GPUs)" if USE_MULTI_GPU else ""))
print(f"Num Workers: {NUM_WORKERS}")
print(f"æ¨¡å‹: {MODELS_TO_TEST}")
print(f"Top-K è¯„ä¼°: {'å¯ç”¨' if ENABLE_TOPK else 'ç¦ç”¨'} (K={TOPK_VALUES})")
print(f"Top-K é‡‡æ ·ç­–ç•¥: {TOPK_SAMPLE_CONFIG} (auto=ml-100kå…¨é‡/ml-1mé‡‡æ ·2000)")
print(f"å¿«é€Ÿæ¨¡å¼: {args.quick}")
print(f"TensorBoard: {'å¯ç”¨' if ENABLE_TENSORBOARD else 'ç¦ç”¨'} (æ—¥å¿—ç›®å½•: {TENSORBOARD_LOG_DIR})")
print("=" * 80)


# ========================================
# æ¶ˆèå®éªŒçš„æ³¨æ„åŠ›å˜ä½“
# ========================================

class TimeDecayRichAttention(nn.Module):
    """æ—¶é—´è¡°å‡æ³¨æ„åŠ›"""
    
    def __init__(self, input_dim, hidden_dims=[64, 32], time_decay=0.1):
        super().__init__()
        self.time_decay = time_decay
        mlp_input = 4 * input_dim
        layers = []
        prev_dim = mlp_input
        for hidden_dim in hidden_dims:
            layers.append(nn.Linear(prev_dim, hidden_dim))
            layers.append(nn.PReLU())
            prev_dim = hidden_dim
        layers.append(nn.Linear(prev_dim, 1))
        self.attention_mlp = nn.Sequential(*layers)
    
    def forward(self, query, keys, keys_mask=None):
        batch_size, seq_len, dim = keys.shape
        query_expanded = query.unsqueeze(1).expand(-1, seq_len, -1)
        attention_input = torch.cat([
            keys, query_expanded,
            keys * query_expanded,
            keys - query_expanded
        ], dim=-1)
        attention_scores = self.attention_mlp(attention_input).squeeze(-1)
        
        positions = torch.arange(seq_len, device=keys.device).float()
        time_weights = torch.exp(self.time_decay * (positions - seq_len + 1))
        attention_scores = attention_scores * time_weights.unsqueeze(0)
        
        if keys_mask is not None:
            mask_bool = keys_mask.bool()
            attention_scores = attention_scores.masked_fill(~mask_bool, float('-inf'))
        attention_weights = F.softmax(attention_scores, dim=-1)
        # å¤„ç†å…¨é›¶maskçš„æƒ…å†µï¼ˆé¿å…NaNï¼‰
        attention_weights = torch.where(
            torch.isnan(attention_weights),
            torch.zeros_like(attention_weights),
            attention_weights
        )
        weighted_sum = torch.sum(attention_weights.unsqueeze(-1) * keys, dim=1)
        return weighted_sum, attention_weights


class MultiHeadRichAttention(nn.Module):
    """å¤šå¤´æ³¨æ„åŠ›"""
    
    def __init__(self, input_dim, num_heads=4, hidden_dims=[64, 32]):
        super().__init__()
        self.num_heads = num_heads
        self.attention_heads = nn.ModuleList([
            self._build_attention_mlp(4 * input_dim, hidden_dims)
            for _ in range(num_heads)
        ])
        self.output_proj = nn.Linear(input_dim, input_dim)
    
    def _build_attention_mlp(self, input_dim, hidden_dims):
        layers = []
        prev_dim = input_dim
        for hidden_dim in hidden_dims:
            layers.append(nn.Linear(prev_dim, hidden_dim))
            layers.append(nn.PReLU())
            prev_dim = hidden_dim
        layers.append(nn.Linear(prev_dim, 1))
        return nn.Sequential(*layers)
    
    def forward(self, query, keys, keys_mask=None):
        batch_size, seq_len, dim = keys.shape
        query_expanded = query.unsqueeze(1).expand(-1, seq_len, -1)
        attention_input = torch.cat([
            keys, query_expanded,
            keys * query_expanded,
            keys - query_expanded
        ], dim=-1)
        
        head_outputs = []
        for head in self.attention_heads:
            scores = head(attention_input).squeeze(-1)
            if keys_mask is not None:
                mask_bool = keys_mask.bool()
                scores = scores.masked_fill(~mask_bool, float('-inf'))
            weights = F.softmax(scores, dim=-1)
            # å¤„ç†å…¨é›¶maskçš„æƒ…å†µï¼ˆé¿å…NaNï¼‰
            weights = torch.where(
                torch.isnan(weights),
                torch.zeros_like(weights),
                weights
            )
            output = torch.sum(weights.unsqueeze(-1) * keys, dim=1)
            head_outputs.append(output)
        
        combined = torch.stack(head_outputs, dim=1).mean(dim=1)
        return self.output_proj(combined), None


class DINRichVariant(nn.Module):
    """DIN æ¶ˆèå˜ä½“ - ä¿®å¤ç‰ˆ"""
    
    def __init__(self, num_items, num_users, feature_dims, embedding_dim=64,
                 attention_type='base', enhanced_mlp=False):
        super().__init__()
        self.attention_type = attention_type
        self.enhanced_mlp = enhanced_mlp
        self.embedding_dim = embedding_dim
        
        # åŸºç¡€åµŒå…¥
        self.item_embedding = nn.Embedding(num_items + 1, embedding_dim, padding_idx=0)
        self.user_embedding = nn.Embedding(num_users + 1, embedding_dim, padding_idx=0)
        
        # ç‰¹å¾åµŒå…¥ (ä¸ DINRichLite ä¸€è‡´)
        self.genre_embedding = nn.Embedding(
            feature_dims.get('primary_genre', 20) + 1, embedding_dim // 4, padding_idx=0
        )
        self.year_embedding = nn.Embedding(
            feature_dims.get('year_bucket', 10) + 1, embedding_dim // 4, padding_idx=0
        )
        self.age_embedding = nn.Embedding(
            feature_dims.get('age_bucket', 10) + 1, embedding_dim // 4
        )
        self.gender_embedding = nn.Embedding(3, embedding_dim // 4)
        self.occupation_embedding = nn.Embedding(
            feature_dims.get('occupation', 25) + 1, embedding_dim // 4
        )
        
        # åºåˆ—åµŒå…¥æ€»ç»´åº¦: item + genre + year
        seq_embed_dim = embedding_dim + embedding_dim // 4 + embedding_dim // 4
        
        # é€‰æ‹©æ³¨æ„åŠ›ç±»å‹
        if attention_type == 'time_decay':
            self.attention = TimeDecayRichAttention(seq_embed_dim)
        elif attention_type == 'multi_head':
            self.attention = MultiHeadRichAttention(seq_embed_dim, num_heads=4)
        else:
            self.attention = AttentionLayer(seq_embed_dim)
        
        # MLP è¾“å…¥: interest + target + seq_mean + user_features
        mlp_input_dim = (
            seq_embed_dim +     # interest_emb
            seq_embed_dim +     # target_emb  
            seq_embed_dim +     # seq_mean
            embedding_dim +     # user_emb
            embedding_dim // 4 + # age
            embedding_dim // 4 + # gender
            embedding_dim // 4   # occupation
        )
        
        if enhanced_mlp:
            self.mlp = nn.Sequential(
                nn.Linear(mlp_input_dim, 256),
                nn.BatchNorm1d(256),
                nn.PReLU(),
                nn.Dropout(0.2),
                nn.Linear(256, 128),
                nn.BatchNorm1d(128),
                nn.PReLU(),
                nn.Dropout(0.2),
                nn.Linear(128, 64),
                nn.PReLU(),
                nn.Linear(64, 1)
            )
        else:
            # åŸºç¡€ MLP ä¹Ÿéœ€è¦ BatchNorm å’Œ Dropout é˜²æ­¢è¿‡æ‹Ÿåˆ
            self.mlp = nn.Sequential(
                nn.Linear(mlp_input_dim, 256),
                nn.BatchNorm1d(256),
                nn.PReLU(),
                nn.Dropout(0.2),
                nn.Linear(256, 128),
                nn.BatchNorm1d(128),
                nn.PReLU(),
                nn.Dropout(0.2),
                nn.Linear(128, 64),
                nn.PReLU(),
                nn.Linear(64, 1)
            )
    
    def forward(self, batch):
        # åºåˆ—
        item_seq = batch['item_seq']  # [B, L]
        seq_mask = batch['item_seq_mask']  # [B, L]
        
        # åºåˆ—åµŒå…¥
        item_emb = self.item_embedding(item_seq)  # [B, L, D]
        genre_emb = self.genre_embedding(batch['history_genres'])  # [B, L, D/4]
        year_emb = self.year_embedding(batch['history_years'])  # [B, L, D/4]
        seq_emb = torch.cat([item_emb, genre_emb, year_emb], dim=-1)  # [B, L, D+D/2]
        
        # ç›®æ ‡ç‰©å“åµŒå…¥
        target_item_emb = self.item_embedding(batch['target_item'])  # [B, D]
        target_genre_emb = self.genre_embedding(batch['item_genre'])  # [B, D/4]
        target_year_emb = self.year_embedding(batch['item_year'])  # [B, D/4]
        target_emb = torch.cat([target_item_emb, target_genre_emb, target_year_emb], dim=-1)
        
        # ç”¨æˆ·åµŒå…¥
        user_emb = self.user_embedding(batch['user_id'])
        age_emb = self.age_embedding(batch['user_age'])
        gender_emb = self.gender_embedding(batch['user_gender'])
        occupation_emb = self.occupation_embedding(batch['user_occupation'])
        
        # æ³¨æ„åŠ›
        interest_emb, _ = self.attention(target_emb, seq_emb, seq_mask)
        
        # åºåˆ—å¹³å‡
        seq_mean = (seq_emb * seq_mask.unsqueeze(-1)).sum(dim=1) / (seq_mask.sum(dim=1, keepdim=True) + 1e-8)
        
        # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
        mlp_input = torch.cat([
            interest_emb, target_emb, seq_mean,
            user_emb, age_emb, gender_emb, occupation_emb
        ], dim=-1)
        
        logits = self.mlp(mlp_input).squeeze(-1)
        return logits


# ========================================
# æ··åˆç²¾æ’æ¨¡å—
# ========================================

class HybridRanker:
    """DIN + LightGBM æ··åˆç²¾æ’"""
    
    def __init__(self, din_model, device='cpu'):
        self.din_model = din_model
        self.device = device
        self.lgb_model = None
    
    @torch.no_grad()
    def extract_din_features(self, data_loader):
        """æå– DIN åµŒå…¥ä½œä¸ºç‰¹å¾"""
        self.din_model.eval()
        self.din_model.to(self.device)
        
        all_embeddings = []
        all_scores = []
        all_labels = []
        
        for batch in data_loader:
            batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                     for k, v in batch.items()}
            
            # è·å–åµŒå…¥
            item_seq = batch['item_seq']
            seq_emb = self.din_model.item_embedding(item_seq)
            target_emb = self.din_model.item_embedding(batch['target_item'])
            user_emb = self.din_model.user_embedding(batch['user_id'])
            
            seq_mask = (item_seq > 0).float()
            seq_mean = (seq_emb * seq_mask.unsqueeze(-1)).sum(dim=1) / (seq_mask.sum(dim=1, keepdim=True) + 1e-8)
            
            # æ‹¼æ¥ç‰¹å¾
            features = torch.cat([target_emb, user_emb, seq_mean], dim=-1)
            all_embeddings.append(features.cpu().numpy())
            
            # DIN åˆ†æ•°
            score = torch.sigmoid(self.din_model(batch))
            all_scores.append(score.cpu().numpy())
            all_labels.append(batch['label'].cpu().numpy())
        
        embeddings = np.concatenate(all_embeddings, axis=0)
        scores = np.concatenate(all_scores, axis=0)
        labels = np.concatenate(all_labels, axis=0)
        
        # æ‹¼æ¥ DIN åˆ†æ•°ä½œä¸ºç‰¹å¾
        features = np.column_stack([embeddings, scores])
        return features, labels
    
    def train_lgb(self, train_loader, valid_loader):
        """è®­ç»ƒ LightGBM"""
        if not HAS_LIGHTGBM:
            return None
        
        X_train, y_train = self.extract_din_features(train_loader)
        X_valid, y_valid = self.extract_din_features(valid_loader)
        
        params = {
            'objective': 'binary',
            'metric': 'auc',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.05,
            'feature_fraction': 0.8,
            'verbose': -1,
            'random_state': 2020
        }
        
        train_data = lgb.Dataset(X_train, label=y_train)
        valid_data = lgb.Dataset(X_valid, label=y_valid)
        
        self.lgb_model = lgb.train(
            params, train_data,
            num_boost_round=300,
            valid_sets=[valid_data],
            callbacks=[lgb.early_stopping(30), lgb.log_evaluation(0)]
        )
        
        return self.lgb_model
    
    def evaluate(self, test_loader):
        """è¯„ä¼°æ··åˆæ¨¡å‹"""
        from sklearn.metrics import roc_auc_score, log_loss
        
        X_test, y_test = self.extract_din_features(test_loader)
        y_pred = self.lgb_model.predict(X_test)
        
        auc = roc_auc_score(y_test, y_pred)
        logloss = log_loss(y_test, y_pred)
        
        return {'auc': auc, 'logloss': logloss}


# ========================================
# å®éªŒä¸€ï¼šåºåˆ—é•¿åº¦æ•æ„Ÿæ€§ + æ¨¡å‹å¯¹æ¯”
# ========================================

def run_experiment1(dataset_name):
    """å®éªŒä¸€ï¼šä¸åŒåºåˆ—é•¿åº¦ä¸‹å„æ¨¡å‹çš„è¡¨ç°"""
    print("\n" + "=" * 80)
    print(f"ğŸ“Š å®éªŒä¸€ï¼šåºåˆ—é•¿åº¦æ•æ„Ÿæ€§ + æ¨¡å‹å¯¹æ¯” [{dataset_name}]")
    print("=" * 80)
    
    results = []
    
    for seq_length in SEQ_LENGTHS:
        print(f"\nğŸ”¬ åºåˆ—é•¿åº¦: {seq_length}")
        
        # è·å– Top-K è¯„ä¼°æ•°æ®ï¼ˆä»…åœ¨å¯ç”¨æ—¶ï¼‰
        eval_data, fp_eval, ie_eval = None, None, None
        if ENABLE_TOPK:
            eval_data, eval_info, fp_eval, ie_eval = get_topk_eval_data(
                data_dir='./data',
                dataset_name=dataset_name,
                max_seq_length=seq_length,
                num_neg_samples=NUM_NEG_SAMPLES
            )
            # æ™ºèƒ½é‡‡æ ·ç”¨æˆ·ï¼ˆæ ¹æ®æ•°æ®é›†è‡ªåŠ¨å†³å®šï¼‰
            topk_sample = get_topk_sample_users(dataset_name, TOPK_SAMPLE_CONFIG)
            if topk_sample and len(eval_data) > topk_sample:
                import random
                random.seed(2020)
                eval_data = random.sample(eval_data, topk_sample)
                print(f"  (Top-K é‡‡æ · {topk_sample}/{eval_info['num_users']} ç”¨æˆ·ï¼Œè¯¯å·®Â±{100*1.96/topk_sample**0.5:.1f}%)")
            else:
                print(f"  (Top-K å…¨é‡è¯„ä¼° {len(eval_data)} ç”¨æˆ·)")
        
        for model_name in MODELS_TO_TEST:
            print(f"  ğŸš€ {model_name}...", end=" ", flush=True)
            
            # è‡ªé€‚åº” batch sizeï¼ˆSASRec é•¿åºåˆ—éœ€è¦å‡å°ï¼‰
            adaptive_batch = get_adaptive_batch_size(model_name, seq_length, BATCH_SIZE)
            if adaptive_batch != BATCH_SIZE:
                print(f"(batch={adaptive_batch}) ", end="", flush=True)
            
            # ä¸ºæ¯ä¸ªæ¨¡å‹é‡æ–°åŠ è½½æ•°æ®ï¼ˆbatch size å¯èƒ½ä¸åŒï¼‰
            train_loader, valid_loader, test_loader, dataset_info, fp = get_rich_dataloaders(
                data_dir='./data',
                dataset_name=dataset_name,
                max_seq_length=seq_length,
                batch_size=adaptive_batch,
                num_workers=NUM_WORKERS,
                prefetch_factor=PREFETCH_FACTOR
            )
            
            try:
                if model_name == 'DIN':
                    model = DINRichLite(
                        num_items=dataset_info['num_items'],
                        num_users=dataset_info['num_users'],
                        feature_dims=dataset_info['feature_dims'],
                        embedding_dim=EMBEDDING_DIM
                    )
                elif model_name == 'GRU4Rec':
                    model = GRU4Rec(
                        num_items=dataset_info['num_items'],
                        num_users=dataset_info['num_users'],
                        feature_dims=dataset_info['feature_dims'],
                        embedding_dim=EMBEDDING_DIM,
                        hidden_dim=EMBEDDING_DIM
                    )
                elif model_name == 'SASRec':
                    model = SASRec(
                        num_items=dataset_info['num_items'],
                        num_users=dataset_info['num_users'],
                        feature_dims=dataset_info['feature_dims'],
                        embedding_dim=EMBEDDING_DIM,
                        num_heads=2,
                        num_layers=2,
                        max_seq_len=seq_length
                    )
                elif model_name == 'NARM':
                    model = NARM(
                        num_items=dataset_info['num_items'],
                        num_users=dataset_info['num_users'],
                        feature_dims=dataset_info['feature_dims'],
                        embedding_dim=EMBEDDING_DIM,
                        hidden_dim=EMBEDDING_DIM
                    )
                elif model_name == 'AvgPool':
                    model = SimpleAveragePoolingRich(
                        num_items=dataset_info['num_items'],
                        num_users=dataset_info['num_users'],
                        feature_dims=dataset_info['feature_dims'],
                        embedding_dim=EMBEDDING_DIM
                    )
                
                # åˆ›å»ºè®­ç»ƒå™¨ - 3x4090å……åˆ†åˆ©ç”¨å¤šGPU
                trainer = RichTrainer(
                    model=model, 
                    device=DEVICE, 
                    use_multi_gpu=USE_MULTI_GPU,
                    use_tensorboard=ENABLE_TENSORBOARD,
                    log_dir=TENSORBOARD_LOG_DIR,
                    experiment_name=f'exp1_{dataset_name}_{model_name}_seq{seq_length}'
                )
                t1 = time.time()
                train_result = trainer.fit(
                    train_loader=train_loader,
                    valid_loader=valid_loader,
                    epochs=EPOCHS,
                    early_stopping_patience=10,
                    show_progress=False
                )
                train_time = time.time() - t1
                
                # CTR æŒ‡æ ‡
                test_metrics = trainer.evaluate(test_loader)
                speed = measure_inference_speed_rich(trainer.raw_model, test_loader, DEVICE)
                
                result_entry = {
                    'experiment': 'exp1_seq_model',
                    'dataset': dataset_name,
                    'seq_length': seq_length,
                    'model': model_name,
                    'test_auc': test_metrics['auc'],
                    'test_logloss': test_metrics['logloss'],
                    'best_valid_auc': train_result['best_valid_auc'],
                    'train_time_sec': train_time,
                    'qps': speed['qps'],
                    'num_params': sum(p.numel() for p in trainer.raw_model.parameters()),
                    'status': 'success'
                }
                
                # Top-K æŒ‡æ ‡ï¼ˆä»…åœ¨å¯ç”¨æ—¶ï¼‰
                if ENABLE_TOPK and eval_data is not None:
                    topk_metrics = trainer.evaluate_topk(
                        eval_data=eval_data,
                        feature_processor=fp_eval,
                        interaction_extractor=ie_eval,
                        max_seq_length=seq_length,
                        ks=TOPK_VALUES,
                        show_progress=False
                    )
                    result_entry.update(topk_metrics)
                    print(f"AUC={test_metrics['auc']:.4f}, HR@10={topk_metrics['HR@10']:.4f}, NDCG@10={topk_metrics['NDCG@10']:.4f}, Time={train_time:.1f}s")
                else:
                    print(f"AUC={test_metrics['auc']:.4f}, Time={train_time:.1f}s")
                
                results.append(result_entry)
                
            except Exception as e:
                print(f"âŒ {str(e)[:50]}")
                results.append({
                    'experiment': 'exp1_seq_model',
                    'dataset': dataset_name,
                    'seq_length': seq_length,
                    'model': model_name,
                    'test_auc': None,
                    'status': f'error: {str(e)[:100]}'
                })
    
    return results


# ========================================
# å®éªŒäºŒï¼šæ–¹æ³•å¯¹æ¯” + LightGBM + æ··åˆç²¾æ’
# ========================================

def run_experiment2(dataset_name):
    """å®éªŒäºŒï¼šDIN vs ä¼ ç»Ÿæ–¹æ³• + æ··åˆç²¾æ’"""
    print("\n" + "=" * 80)
    print(f"ğŸ“Š å®éªŒäºŒï¼šæ–¹æ³•å¯¹æ¯” + æ··åˆç²¾æ’ [{dataset_name}]")
    print("=" * 80)
    
    results = []
    seq_length = 50
    
    train_loader, valid_loader, test_loader, dataset_info, fp = get_rich_dataloaders(
        data_dir='./data',
        dataset_name=dataset_name,
        max_seq_length=seq_length,
        batch_size=BATCH_SIZE,
        num_workers=NUM_WORKERS,
        prefetch_factor=PREFETCH_FACTOR
    )
    
    # è·å– Top-K è¯„ä¼°æ•°æ®ï¼ˆä»…åœ¨å¯ç”¨æ—¶ï¼‰
    eval_data, fp_eval, ie_eval = None, None, None
    if ENABLE_TOPK:
        eval_data, eval_info, fp_eval, ie_eval = get_topk_eval_data(
            data_dir='./data',
            dataset_name=dataset_name,
            max_seq_length=seq_length,
            num_neg_samples=NUM_NEG_SAMPLES
        )
        # æ™ºèƒ½é‡‡æ ·ç”¨æˆ·ï¼ˆæ ¹æ®æ•°æ®é›†è‡ªåŠ¨å†³å®šï¼‰
        topk_sample = get_topk_sample_users(dataset_name, TOPK_SAMPLE_CONFIG)
        if topk_sample and len(eval_data) > topk_sample:
            import random
            random.seed(2020)
            eval_data = random.sample(eval_data, topk_sample)
            print(f"  (Top-K é‡‡æ · {topk_sample}/{eval_info['num_users']} ç”¨æˆ·)")
        else:
            print(f"  (Top-K å…¨é‡è¯„ä¼° {len(eval_data)} ç”¨æˆ·)")
    
    din_model = None  # ä¿å­˜ç”¨äºæ··åˆç²¾æ’
    din_train_time = 0  # ä¿å­˜ DIN è®­ç»ƒæ—¶é—´ï¼Œç”¨äºæ··åˆç²¾æ’å…¬å¹³å¯¹æ¯”
    din_num_params = 0  # ä¿å­˜ DIN å‚æ•°é‡
    
    # æµ‹è¯•å„æ·±åº¦æ¨¡å‹
    for model_name in MODELS_TO_TEST:
        print(f"  ğŸš€ {model_name}...", end=" ", flush=True)
        
        try:
            if model_name == 'DIN':
                model = DINRichLite(
                    num_items=dataset_info['num_items'],
                    num_users=dataset_info['num_users'],
                    feature_dims=dataset_info['feature_dims'],
                    embedding_dim=EMBEDDING_DIM
                )
            elif model_name == 'GRU4Rec':
                model = GRU4Rec(
                    num_items=dataset_info['num_items'],
                    num_users=dataset_info['num_users'],
                    feature_dims=dataset_info['feature_dims'],
                    embedding_dim=EMBEDDING_DIM,
                    hidden_dim=EMBEDDING_DIM
                )
            elif model_name == 'SASRec':
                model = SASRec(
                    num_items=dataset_info['num_items'],
                    num_users=dataset_info['num_users'],
                    feature_dims=dataset_info['feature_dims'],
                    embedding_dim=EMBEDDING_DIM,
                    num_heads=2,
                    num_layers=2,
                    max_seq_len=seq_length
                )
            elif model_name == 'NARM':
                model = NARM(
                    num_items=dataset_info['num_items'],
                    num_users=dataset_info['num_users'],
                    feature_dims=dataset_info['feature_dims'],
                    embedding_dim=EMBEDDING_DIM,
                    hidden_dim=EMBEDDING_DIM
                )
            elif model_name == 'AvgPool':
                model = SimpleAveragePoolingRich(
                    num_items=dataset_info['num_items'],
                    num_users=dataset_info['num_users'],
                    feature_dims=dataset_info['feature_dims'],
                    embedding_dim=EMBEDDING_DIM
                )
            
            # 3x4090å……åˆ†åˆ©ç”¨å¤šGPU
            trainer = RichTrainer(
                model=model, 
                device=DEVICE, 
                use_multi_gpu=USE_MULTI_GPU,
                use_tensorboard=ENABLE_TENSORBOARD,
                log_dir=TENSORBOARD_LOG_DIR,
                experiment_name=f'exp2_{dataset_name}_{model_name}'
            )
            t1 = time.time()
            train_result = trainer.fit(
                train_loader=train_loader,
                valid_loader=valid_loader,
                epochs=EPOCHS,
                early_stopping_patience=10,
                show_progress=False
            )
            train_time = time.time() - t1
            
            # ä¿å­˜ DIN æ¨¡å‹å’Œè®­ç»ƒæ—¶é—´ï¼ˆç”¨äºæ··åˆç²¾æ’ï¼‰
            if model_name == 'DIN':
                din_model = trainer.raw_model
                din_train_time = train_time
                din_num_params = sum(p.numel() for p in trainer.raw_model.parameters())
            
            # CTR æŒ‡æ ‡
            test_metrics = trainer.evaluate(test_loader)
            speed = measure_inference_speed_rich(trainer.raw_model, test_loader, DEVICE)
            
            result_entry = {
                'experiment': 'exp2_method_compare',
                'dataset': dataset_name,
                'model': model_name,
                'test_auc': test_metrics['auc'],
                'test_logloss': test_metrics['logloss'],
                'train_time_sec': train_time,
                'qps': speed['qps'],
                'num_params': sum(p.numel() for p in trainer.raw_model.parameters()),
                'status': 'success'
            }
            
            # Top-K æŒ‡æ ‡ï¼ˆä»…åœ¨å¯ç”¨æ—¶ï¼‰
            if ENABLE_TOPK and eval_data is not None:
                topk_metrics = trainer.evaluate_topk(
                    eval_data=eval_data,
                    feature_processor=fp_eval,
                    interaction_extractor=ie_eval,
                    max_seq_length=seq_length,
                    ks=TOPK_VALUES,
                    show_progress=False
                )
                result_entry.update(topk_metrics)
                print(f"AUC={test_metrics['auc']:.4f}, HR@10={topk_metrics['HR@10']:.4f}, NDCG@10={topk_metrics['NDCG@10']:.4f}")
            else:
                print(f"AUC={test_metrics['auc']:.4f}")
            
            results.append(result_entry)
            
        except Exception as e:
            print(f"âŒ {str(e)[:50]}")
            results.append({
                'experiment': 'exp2_method_compare',
                'dataset': dataset_name,
                'model': model_name,
                'test_auc': None,
                'status': f'error: {str(e)[:100]}'
            })
    
    # LightGBM å•ç‹¬
    if HAS_LIGHTGBM:
        print("  ğŸš€ LightGBM (pure)...", end=" ", flush=True)
        try:
            from sklearn.metrics import roc_auc_score, log_loss
            from sklearn.model_selection import train_test_split
            
            data_path = os.path.join('./data', dataset_name)
            if dataset_name == 'ml-100k':
                interactions = pd.read_csv(
                    os.path.join(data_path, 'u.data'),
                    sep='\t', names=['user_id', 'item_id', 'rating', 'timestamp']
                )
            else:
                interactions = pd.read_csv(
                    os.path.join(data_path, 'ratings.dat'),
                    sep='::', names=['user_id', 'item_id', 'rating', 'timestamp'],
                    engine='python'
                )
            
            interaction_extractor = InteractionFeatureExtractor(interactions)
            X, y, feature_names = prepare_lightgbm_features(
                interactions, fp, interaction_extractor, max_seq_length=seq_length
            )
            
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2020)
            X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.125, random_state=2020)
            
            params = {
                'objective': 'binary', 'metric': 'auc', 'boosting_type': 'gbdt',
                'num_leaves': 31, 'learning_rate': 0.05, 'feature_fraction': 0.8,
                'verbose': -1, 'random_state': 2020
            }
            
            train_data = lgb.Dataset(X_train, label=y_train)
            valid_data = lgb.Dataset(X_valid, label=y_valid)
            
            t1 = time.time()
            lgb_model = lgb.train(
                params, train_data, num_boost_round=500,
                valid_sets=[valid_data],
                callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]
            )
            train_time = time.time() - t1
            
            y_pred = lgb_model.predict(X_test)
            test_auc = roc_auc_score(y_test, y_pred)
            
            # LightGBM å‚æ•°é‡ä¼°ç®—ï¼ˆå¶å­æ•° Ã— æ ‘çš„æ•°é‡ Ã— ç‰¹å¾æ•°ï¼‰
            lgb_num_trees = lgb_model.num_trees()
            lgb_num_leaves = params['num_leaves']
            lgb_num_params = lgb_num_trees * lgb_num_leaves  # è¿‘ä¼¼å‚æ•°é‡
            
            results.append({
                'experiment': 'exp2_method_compare',
                'dataset': dataset_name,
                'model': 'LightGBM',
                'test_auc': test_auc,
                'train_time_sec': train_time,
                'num_params': lgb_num_params,
                'status': 'success'
            })
            print(f"AUC={test_auc:.4f}, params={lgb_num_params}")
            
        except Exception as e:
            print(f"âŒ {str(e)[:50]}")
            results.append({
                'experiment': 'exp2_method_compare',
                'dataset': dataset_name,
                'model': 'LightGBM',
                'test_auc': None,
                'status': f'error: {str(e)[:100]}'
            })
    
    # æ··åˆç²¾æ’ï¼šDIN + LightGBM
    if HAS_LIGHTGBM and din_model is not None:
        print("  ğŸš€ Hybrid (DIN + LightGBM)...", end=" ", flush=True)
        try:
            hybrid = HybridRanker(din_model, device=DEVICE)
            t1 = time.time()
            hybrid.train_lgb(train_loader, valid_loader)
            lgb_train_time = time.time() - t1

            # å…¬å¹³å¯¹æ¯”ï¼šæ€»è®­ç»ƒæ—¶é—´ = DINè®­ç»ƒæ—¶é—´ + LightGBMè®­ç»ƒæ—¶é—´
            total_train_time = din_train_time + lgb_train_time

            test_metrics = hybrid.evaluate(test_loader)

            # Top-K æŒ‡æ ‡ï¼ˆä¸å…¶ä»–æ¨¡å‹å¯¹é½ï¼‰
            topk_metrics = {}
            if ENABLE_TOPK and eval_data is not None:
                # ä½¿ç”¨å®Œæ•´çš„ Hybrid æµç¨‹ï¼šDIN æå–ç‰¹å¾ -> LightGBM é¢„æµ‹
                from tqdm import tqdm
                from data_loader import build_topk_batch_multi
                all_labels = []
                all_scores = []
                for entry in tqdm(eval_data, desc="Hybrid Top-K"):
                    # æ„å»ºå•ç”¨æˆ·çš„å€™é€‰ batch
                    batch = build_topk_batch_multi(
                        entry, fp_eval, ie_eval, seq_length, DEVICE
                    )
                    
                    # ç”¨å®Œæ•´çš„ Hybrid æµç¨‹é¢„æµ‹åˆ†æ•°
                    with torch.no_grad():
                        # DIN æå–ç‰¹å¾
                        features, _ = hybrid.extract_din_features([batch])
                        # LightGBM é¢„æµ‹
                        scores = hybrid.lgb_model.predict(features)
                    
                    all_scores.append(scores)
                    labels = [1 if c == entry['ground_truth'] else 0 for c in entry['candidates']]
                    all_labels.append(np.array(labels))
                # æ‹¼æ¥
                all_scores = np.stack(all_scores)
                all_labels = np.stack(all_labels)
                # è®¡ç®— Top-K æŒ‡æ ‡
                def calc_topk_metrics(scores, labels, ks):
                    metrics = {}
                    for k in ks:
                        # HR@K
                        hits = 0
                        ndcg = 0
                        mrr = 0
                        for s, l in zip(scores, labels):
                            idx = np.argsort(-s)[:k]
                            rel = l[idx]
                            hits += rel.max()
                            if rel.max() > 0:
                                rank = np.where(rel == 1)[0][0] + 1
                                ndcg += 1 / np.log2(rank + 1)
                                mrr += 1 / rank
                        n = len(scores)
                        hr_k = hits / n
                        metrics[f'HR@{k}'] = hr_k
                        metrics[f'Recall@{k}'] = hr_k  # å• GT ç­‰äº HR
                        metrics[f'NDCG@{k}'] = ndcg / n
                        metrics[f'MRR@{k}'] = mrr / n
                        metrics[f'Precision@{k}'] = hr_k / k
                    return metrics
                topk_metrics = calc_topk_metrics(all_scores, all_labels, TOPK_VALUES)
                print(f"AUC={test_metrics['auc']:.4f}, HR@10={topk_metrics['HR@10']:.4f}, NDCG@10={topk_metrics['NDCG@10']:.4f}, total_time={total_train_time:.2f}s (DIN:{din_train_time:.2f}s + LGB:{lgb_train_time:.2f}s)")
            else:
                print(f"AUC={test_metrics['auc']:.4f}, total_time={total_train_time:.2f}s (DIN:{din_train_time:.2f}s + LGB:{lgb_train_time:.2f}s)")

            # Hybrid å‚æ•°é‡ = DINå‚æ•°é‡ + LightGBMå‚æ•°é‡ï¼ˆä¼°ç®—ï¼‰
            lgb_num_params_hybrid = hybrid.lgb_model.num_trees() * 31 if hybrid.lgb_model else 0
            total_num_params = din_num_params + lgb_num_params_hybrid

            result_entry = {
                'experiment': 'exp2_hybrid',
                'dataset': dataset_name,
                'model': 'DIN+LightGBM',
                'test_auc': test_metrics['auc'],
                'test_logloss': test_metrics['logloss'],
                'train_time_sec': total_train_time,
                'din_train_time': din_train_time,
                'lgb_train_time': lgb_train_time,
                'num_params': total_num_params,
                'din_num_params': din_num_params,
                'lgb_num_params': lgb_num_params_hybrid,
                'status': 'success'
            }
            result_entry.update(topk_metrics)
            results.append(result_entry)

        except Exception as e:
            print(f"âŒ {str(e)[:50]}")
            results.append({
                'experiment': 'exp2_hybrid',
                'dataset': dataset_name,
                'model': 'DIN+LightGBM',
                'test_auc': None,
                'status': f'error: {str(e)[:100]}'
            })

    return results


# ========================================
# å®éªŒä¸‰ï¼šDIN æ¶ˆèå®éªŒ
# ========================================

def run_experiment3(dataset_name):
    """å®éªŒä¸‰ï¼šDIN æ”¹è¿›æ¶ˆèå®éªŒ"""
    print("\n" + "=" * 80)
    print(f"ğŸ“Š å®éªŒä¸‰ï¼šDIN æ¶ˆèå®éªŒ [{dataset_name}]")
    print("=" * 80)
    
    results = []
    seq_length = 50
    
    train_loader, valid_loader, test_loader, dataset_info, fp = get_rich_dataloaders(
        data_dir='./data',
        dataset_name=dataset_name,
        max_seq_length=seq_length,
        batch_size=BATCH_SIZE,
        num_workers=NUM_WORKERS,
        prefetch_factor=PREFETCH_FACTOR
    )
    
    # è·å– Top-K è¯„ä¼°æ•°æ®ï¼ˆä»…åœ¨å¯ç”¨æ—¶ï¼‰
    eval_data, fp_eval, ie_eval = None, None, None
    if ENABLE_TOPK:
        eval_data, eval_info, fp_eval, ie_eval = get_topk_eval_data(
            data_dir='./data',
            dataset_name=dataset_name,
            max_seq_length=seq_length,
            num_neg_samples=NUM_NEG_SAMPLES
        )
        # æ™ºèƒ½é‡‡æ ·ç”¨æˆ·ï¼ˆæ ¹æ®æ•°æ®é›†è‡ªåŠ¨å†³å®šï¼‰
        topk_sample = get_topk_sample_users(dataset_name, TOPK_SAMPLE_CONFIG)
        if topk_sample and len(eval_data) > topk_sample:
            import random
            random.seed(2020)
            eval_data = random.sample(eval_data, topk_sample)
            print(f"  (Top-K é‡‡æ · {topk_sample}/{eval_info['num_users']} ç”¨æˆ·)")
        else:
            print(f"  (Top-K å…¨é‡è¯„ä¼° {len(eval_data)} ç”¨æˆ·)")
    
    # æ¶ˆèå˜ä½“
    ablation_variants = [
        ('DIN-Base', 'base', False),
        ('DIN-TimeDec', 'time_decay', False),
        ('DIN-MultiHead', 'multi_head', False),
        ('DIN-Enhanced', 'base', True),
        ('DIN-Full', 'time_decay', True),
    ]
    
    for variant_name, attention_type, enhanced_mlp in ablation_variants:
        print(f"  ğŸš€ {variant_name}...", end=" ", flush=True)
        
        try:
            model = DINRichVariant(
                num_items=dataset_info['num_items'],
                num_users=dataset_info['num_users'],
                feature_dims=dataset_info['feature_dims'],
                embedding_dim=EMBEDDING_DIM,
                attention_type=attention_type,
                enhanced_mlp=enhanced_mlp
            )
            
            # 3x4090å……åˆ†åˆ©ç”¨å¤šGPU
            trainer = RichTrainer(
                model=model, 
                device=DEVICE, 
                use_multi_gpu=USE_MULTI_GPU,
                use_tensorboard=ENABLE_TENSORBOARD,
                log_dir=TENSORBOARD_LOG_DIR,
                experiment_name=f'exp3_{dataset_name}_{variant_name}'
            )
            t1 = time.time()
            train_result = trainer.fit(
                train_loader=train_loader,
                valid_loader=valid_loader,
                epochs=EPOCHS,
                early_stopping_patience=10,
                show_progress=False
            )
            train_time = time.time() - t1
            
            # CTR æŒ‡æ ‡
            test_metrics = trainer.evaluate(test_loader)
            speed = measure_inference_speed_rich(trainer.raw_model, test_loader, DEVICE)
            
            result_entry = {
                'experiment': 'exp3_ablation',
                'dataset': dataset_name,
                'variant': variant_name,
                'attention_type': attention_type,
                'enhanced_mlp': enhanced_mlp,
                'test_auc': test_metrics['auc'],
                'test_logloss': test_metrics['logloss'],
                'best_valid_auc': train_result['best_valid_auc'],
                'train_time_sec': train_time,
                'qps': speed['qps'],
                'num_params': sum(p.numel() for p in trainer.raw_model.parameters()),
                'status': 'success'
            }
            
            # Top-K æŒ‡æ ‡ï¼ˆä»…åœ¨å¯ç”¨æ—¶ï¼‰
            if ENABLE_TOPK and eval_data is not None:
                topk_metrics = trainer.evaluate_topk(
                    eval_data=eval_data,
                    feature_processor=fp_eval,
                    interaction_extractor=ie_eval,
                    max_seq_length=seq_length,
                    ks=TOPK_VALUES,
                    show_progress=False
                )
                result_entry.update(topk_metrics)
                print(f"AUC={test_metrics['auc']:.4f}, HR@10={topk_metrics['HR@10']:.4f}, NDCG@10={topk_metrics['NDCG@10']:.4f}")
            else:
                print(f"AUC={test_metrics['auc']:.4f}")
            
            results.append(result_entry)
            
        except Exception as e:
            print(f"âŒ {str(e)[:50]}")
            results.append({
                'experiment': 'exp3_ablation',
                'dataset': dataset_name,
                'variant': variant_name,
                'test_auc': None,
                'status': f'error: {str(e)[:100]}'
            })
    
    return results


# ========================================
# å®éªŒå››ï¼šé«˜çº§æ”¹è¿›å®éªŒ
# ========================================

def run_experiment4(dataset_name, part='all'):
    """
    è¿è¡Œå®éªŒå››ï¼šé«˜çº§æ”¹è¿›å®éªŒ
    
    Args:
        dataset_name: æ•°æ®é›†åç§°
        part: è¿è¡Œå“ªéƒ¨åˆ† ('all', 'adaptive', 'contrastive')
    """
    print(f"\n{'='*60}")
    print(f"ğŸ§ª å®éªŒå››ï¼šé«˜çº§æ”¹è¿›å®éªŒ ({dataset_name})")
    print(f"{'='*60}")
    
    results = []
    
    try:
        # åŠ¨æ€å¯¼å…¥ experiment4 æ¨¡å—
        import importlib.util
        exp4_path = os.path.join(os.path.dirname(__file__), 'experiment4.py')
        
        if not os.path.exists(exp4_path):
            print("âŒ experiment4.py ä¸å­˜åœ¨ï¼Œè·³è¿‡å®éªŒå››")
            return results
            
        spec = importlib.util.spec_from_file_location("experiment4", exp4_path)
        exp4_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(exp4_module)
        
        # è¿è¡Œè‡ªé€‚åº”æ—¶é—´è¡°å‡å®éªŒ
        if part in ['all', 'adaptive']:
            print("\nğŸ“Š Part 1: è‡ªé€‚åº”æ—¶é—´è¡°å‡å®éªŒ")
            print("-" * 40)
            try:
                adaptive_results = exp4_module.run_adaptive_decay_experiment(
                    dataset_name=dataset_name,
                    epochs=EPOCHS,
                    batch_size=BATCH_SIZE,
                    device=DEVICE
                )
                for r in adaptive_results:
                    r['experiment'] = 'exp4_adaptive_decay'
                    r['dataset'] = dataset_name
                results.extend(adaptive_results)
                print(f"âœ… è‡ªé€‚åº”æ—¶é—´è¡°å‡å®éªŒå®Œæˆï¼Œ{len(adaptive_results)} ç»„ç»“æœ")
            except Exception as e:
                print(f"âŒ è‡ªé€‚åº”æ—¶é—´è¡°å‡å®éªŒå¤±è´¥: {e}")
                results.append({
                    'experiment': 'exp4_adaptive_decay',
                    'dataset': dataset_name,
                    'status': f'error: {str(e)[:100]}'
                })
        
        # è¿è¡Œå¯¹æ¯”å­¦ä¹ å®éªŒ
        if part in ['all', 'contrastive']:
            print("\nğŸ“Š Part 2: å¯¹æ¯”å­¦ä¹ å®éªŒ")
            print("-" * 40)
            try:
                contrastive_results = exp4_module.run_contrastive_experiment(
                    dataset_name=dataset_name,
                    epochs=EPOCHS,
                    batch_size=BATCH_SIZE,
                    device=DEVICE
                )
                for r in contrastive_results:
                    r['experiment'] = 'exp4_contrastive'
                    r['dataset'] = dataset_name
                results.extend(contrastive_results)
                print(f"âœ… å¯¹æ¯”å­¦ä¹ å®éªŒå®Œæˆï¼Œ{len(contrastive_results)} ç»„ç»“æœ")
            except Exception as e:
                print(f"âŒ å¯¹æ¯”å­¦ä¹ å®éªŒå¤±è´¥: {e}")
                results.append({
                    'experiment': 'exp4_contrastive',
                    'dataset': dataset_name,
                    'status': f'error: {str(e)[:100]}'
                })
                
    except Exception as e:
        print(f"âŒ å®éªŒå››åŠ è½½å¤±è´¥: {e}")
        results.append({
            'experiment': 'exp4',
            'dataset': dataset_name,
            'status': f'load_error: {str(e)[:100]}'
        })
    
    return results


# ========================================
# ä¸»ç¨‹åº
# ========================================

if __name__ == '__main__':
    all_results = []
    experiment_start = datetime.now()
    
    print(f"\nâ° å®éªŒå¼€å§‹æ—¶é—´: {experiment_start.strftime('%Y-%m-%d %H:%M:%S')}")
    
    for dataset in DATASETS:
        print(f"\n{'='*80}")
        print(f"ğŸ“ æ•°æ®é›†: {dataset.upper()}")
        print(f"{'='*80}")
        
        if 1 in EXPERIMENTS_TO_RUN:
            results1 = run_experiment1(dataset)
            all_results.extend(results1)
        
        if 2 in EXPERIMENTS_TO_RUN:
            results2 = run_experiment2(dataset)
            all_results.extend(results2)
        
        if 3 in EXPERIMENTS_TO_RUN:
            results3 = run_experiment3(dataset)
            all_results.extend(results3)
        
        if 4 in EXPERIMENTS_TO_RUN:
            results4 = run_experiment4(dataset, part=args.exp4_part)
            all_results.extend(results4)
    
    # ä¿å­˜ç»“æœ
    experiment_end = datetime.now()
    total_time = (experiment_end - experiment_start).total_seconds()
    
    df_results = pd.DataFrame(all_results)
    timestamp = experiment_start.strftime('%Y%m%d_%H%M%S')
    
    # CSV
    csv_file = os.path.join(RESULTS_DIR, f'all_results_{timestamp}.csv')
    df_results.to_csv(csv_file, index=False)
    
    # JSON æŠ¥å‘Š
    report = {
        'timestamp': timestamp,
        'device': DEVICE,
        'gpu_name': torch.cuda.get_device_name(0) if DEVICE == 'cuda' else 'CPU',
        'datasets': DATASETS,
        'experiments': EXPERIMENTS_TO_RUN,
        'epochs': EPOCHS,
        'seq_lengths': SEQ_LENGTHS,
        'models': MODELS_TO_TEST,
        'topk_values': TOPK_VALUES,
        'total_time_minutes': total_time / 60,
        'num_results': len(all_results),
        'results': all_results
    }
    
    json_file = os.path.join(RESULTS_DIR, f'report_{timestamp}.json')
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # æ‰“å°æ‘˜è¦
    print("\n" + "=" * 80)
    print("ğŸ“‹ å®éªŒå®Œæˆï¼")
    print("=" * 80)
    print(f"æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
    print(f"å®éªŒæ•°é‡: {len(all_results)}")
    print(f"\nğŸ“‚ ç»“æœæ–‡ä»¶:")
    print(f"   {csv_file}")
    print(f"   {json_file}")
    
    # å„æ•°æ®é›†æœ€ä½³ç»“æœ
    df_success = df_results[df_results['status'] == 'success']
    
    print("\nğŸ“Š å„å®éªŒæœ€ä½³ç»“æœ (CTR æŒ‡æ ‡):")
    for exp_name in df_success['experiment'].unique():
        df_exp = df_success[df_success['experiment'] == exp_name]
        if len(df_exp) > 0 and 'test_auc' in df_exp.columns:
            best = df_exp.loc[df_exp['test_auc'].idxmax()]
            model_col = 'model' if 'model' in best else 'variant'
            print(f"  {exp_name}: {best.get(model_col, 'N/A')} - AUC={best['test_auc']:.4f}")
    
    # Top-K æŒ‡æ ‡æ‘˜è¦
    if 'HR@10' in df_success.columns:
        print("\nğŸ“Š å„å®éªŒæœ€ä½³ç»“æœ (Top-K æŒ‡æ ‡):")
        for exp_name in df_success['experiment'].unique():
            df_exp = df_success[df_success['experiment'] == exp_name]
            if len(df_exp) > 0 and 'NDCG@10' in df_exp.columns and df_exp['NDCG@10'].notna().any():
                best = df_exp.loc[df_exp['NDCG@10'].idxmax()]
                model_col = 'model' if 'model' in best else 'variant'
                print(f"  {exp_name}: {best.get(model_col, 'N/A')} - HR@10={best['HR@10']:.4f}, NDCG@10={best['NDCG@10']:.4f}")
    
    print("=" * 80)
    print("âœ… æ‰€æœ‰å®éªŒå®Œæˆï¼")
